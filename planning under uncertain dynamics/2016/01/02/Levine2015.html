<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Learning contact-rich manipulation skills with guided policy search</title>
    <meta name="description" content="Notes on readings for my qualifying exams.
">

    <link rel="stylesheet" href="/quals/css/main.css">
    <link rel="canonical" href="http://jhamrick.github.io/quals/planning%20under%20uncertain%20dynamics/2016/01/02/Levine2015.html">

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });
    </script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/quals/">Quals Reading Notes</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/quals/about/">About</a>
          
        
          
          <a class="page-link" href="/quals/categories/">Categories</a>
          
        
          
        
          
        
          
        
        <a class="page-link" href="/quals/readings.pdf">Reading List</a>
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Learning contact-rich manipulation skills with guided policy search</h1>
    <p class="post-meta">Jan 2, 2016 • Planning under uncertain dynamics</p>
  </header>

  <article class="post-content">
    <p><span id="Levine2015">Levine, S., Wagener, N., &amp; Abbeel, P. (2015). Learning Contact-Rich Manipulation Skills with Guided Policy Search. <i>Proceedings Of the IEEE International Conference on Robotics and Automation</i>. Retrieved from http://arxiv.org/abs/1501.05611v1</span></p>

<h1 id="summary">Summary</h1>

<p>This paper builds on previous work (Levine &amp; Abbeel, NIPS 2013) that learns policies for object manipulation using a two step process. The first step is to learn local linear-Gaussian controllers for a few specific training examples. Then, the linear-Gaussian controllers are used to train parameters for a more complex policy (e.g., using a neural network) using a method called <em>guided policy search</em>.</p>

<h1 id="methods">Methods</h1>

<p>n/a</p>

<h1 id="algorithm">Algorithm</h1>

<h2 id="linear-gaussian-controllers">Linear-Gaussian controllers</h2>

<p>First, they assume linear-Gaussian dynamics, i.e.:</p>

<script type="math/tex; mode=display">p(\mathbf{x}_{t+1}\vert \mathbf{x}_t,\mathbf{u}_t)=\mathcal{N}(f_{\mathbf{x}t}\mathbf{x}_t+f_{\mathbf{u}t}\mathbf{u}_t, \mathbf{F}_t)</script>

<p>They can fit these dynamics using samples collected under the previous version of the controller, and from there compute the linear-Gaussian controller:</p>

<script type="math/tex; mode=display">p(\mathbf{u}_t\vert \mathbf{x}_t)=\mathcal{N}(\hat{\mathbf{u}}_t+\mathbf{k}_t+\mathbf{K}_t(\mathbf{x}_t-\hat{\mathbf{x}}_t),Q_{\mathbf{u}, \mathbf{u}t}^{-1})</script>

<p>where $Q_{\mathbf{u}, \mathbf{u}t}$ is the Hessian of the $Q$-function, $\mathbf{k}_t=-Q_{\mathbf{u},\mathbf{u}t}^{-1}Q_{\mathbf{u}t}$ and $\mathbf{K}_t=-Q_{\mathbf{u},\mathbf{u}t}^{-1}Q_{\mathbf{u},\mathbf{x}t}$ and (I think?) where $\hat{\mathbf{u}}_t$ and $\hat{\mathbf{x}}_t$ are the mean state and control from the samples. The $Q$-function is computed using a dynamic programming algorithm, which I won’t go into the details of.</p>

<p>The controller is then updated subject to the constraint that the KL-divergence between the trajectory distribution $p(\tau)=\prod_t p(\mathbf{x}_{t+1}\vert \mathbf{x}_t,\mathbf{u}_t)p(\mathbf{u}_t\vert \mathbf{x}_t)$ and the old trajectory distribution is not more than a threshold $\epsilon$. They solve this optimization using dual gradient descent, which I also won’t go into the details of here.</p>

<p>Levine et al. minimize the number of samples needed by also estimating a Gaussain mixture model prior on the global dynamics, and adaptively adjust both the step size $\epsilon$ and sample count according to an estimate of the additional cost at each iteration due to unmodeled changes in the dynamics.</p>

<h2 id="guided-policy-search">Guided policy search</h2>

<p>Given the learned linear-Gaussian dynamics and controller, they can be used to train a more sophisticated policy with large numbers of parameters (e.g., a neural network). Rather than directly computing a policy, supervised learning is used to learn the policy using trajectories sampled from the linear-Gaussian controllers (this is kind of a form of learning-by-demonstration, I think, where the demonstrations are a combination of the actual trajectories run using the linear-Gaussian controller on the real robot, and synthesized trajectories from the linear-Gaussian controllers). The trajectories are then reoptimized as well to better match the state distribution of the policy, i.e.:</p>

<script type="math/tex; mode=display">\min_{\theta,p(\tau)}E_{p(\tau)}[\ell(\tau)]\ \mathrm{s.t.}\ D_{\mathrm{KL}}(p(\mathbf{x}_t)\pi_\theta(\mathbf{u}_t\vert \mathbf{x}_t)\vert\vert p(\mathbf{x}_t, \mathbf{u}_t))=0\ \forall t</script>

<p>where $p(\tau)$ is the trajectory distribution (obtained from the linear-Gaussian dynamics) and $\pi_\theta$ is the parameterized policy. They solve this using another (different) application of dual gradient descent.</p>

<h1 id="takeaways">Takeaways</h1>

<p>This is a cool way to combine deep learning with a more structured modeling approach. Essentially, the linear-Gaussian controllers are learning a generative model of the dynamics for specific motions, from which an optimal policy can be extracted with relatively little computation. The generative model is then used to train the discriminative model (the neural network). It’s an interesting contrast, though, because I generally think of generative models as being <em>more</em> general, whereas in this case it’s actually that there are multiple generative models, each of which is local and therefore relatively fragile. But by combining them together a more powerful and flexible discriminative model can be trained.</p>

<p>Overall, it seems to me that this approach is quite similar similar to the approach taken by <a href="/quals/physical%20reasoning%20without%20dynamics%20models/2015/12/30/Paraschos2015.html">Paraschos et al.</a>, at least in terms of using linear-Gaussian dynamics to learn local (or primitive) motion policies. This paper, though, goes the next step and shows how then those local motion policies can be combined in order to train a more sophisticated and general policy.</p>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Quals Reading Notes</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>Quals Reading Notes</li>
          <li><a href="mailto:"></a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/jhamrick">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">jhamrick</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/jhamrick">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">jhamrick</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">Notes on readings for my qualifying exams.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
