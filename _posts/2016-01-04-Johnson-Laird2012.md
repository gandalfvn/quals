---
layout: post
title: "Inference with mental models"
date: 2016-01-04 21:28:36
category: Mental models
---

{% reference Johnson-Laird2012 %}

# Summary

In this chapter, Johnson-Laird describes the theory of mental models:

> Perception yields models of the world that lies outside us. An understanding of discourse yields models of the world that the speaker describes for us. And thinking, which enables us to anticipate the world and to choose a course of action, relies on internal manipulations of these mental models. The present chapter is about this theory, which it refers to as the *model* theory, and about its experimental corroborations. (pg. 134)

Johnson-Laird first defines what a mental model is. In particular, it follows three principles:

1. Mental models are iconic; that is, they have the same structure of the thing the model represents.
2. Each mental model is the simplest way of describing a possibility (and thus implicitly incorporates other irrelevant possibilities).
3. Mental models only represent what is possible, and not what is impossible.

## Deduction

Next, Johnson-Laird describes how model theory applies to deductive reasoning, and gives empirical evidence for several predictions:

1. Fewer and simpler models require less time to process.
2. People will overlook certain models of premises (e.g. because mental models encode implicit information) and thus produce certain errors.
3. People can detect invalid inferences by coming up with counterexamples. Johnson-Laird emphasizes that there are two types of invalid inferences: first, that the conclusion is inconsistent with the premises (people seem to just be able to detect this inconsistency), and second, the conclusion is consistent with the premises but does not follow from them (people come up with a counterexample).
4. People confidently make "illusory" inferences which are invalid. In particular, "when they think about the truth of one assertion, they fail to think about the consequences of the falsity of other assertions".
5. People who have never performed these sorts of deductions will develop their own strategies for doing so automatically.

## Probabilistic reasoning

**intentional reasoning**: people use heuristics to infer the probability of an event from evidence

**extensional reasoning**: people infer the probability of an event based on different ways the event might occur

**principle of equiprobability**: mental models are uniformly equally probable (unless there is reason to believe otherwise)

## Induction

Johnson-Laird argues that there are two systems of inductive reasoning: one which is *intuitive* (system 1) and which has no access to working memory (and thus can only make fast, but potentially erroneous inferences), and one which is *explicit* (system 2) and which is "slow, voluntary, and conscious". For intuitive inductions, they can be affected by *modulation*, which is the idea that "the meanings of clauses, coreferential links between them, general knowledge, and knowledge of context, can modulate the core meanings of sentential connectives" (pg. 146). This can affect things like property relations (e.g. "if the dish is kidney beans, then its basis is beans" vs. "if the dish is made of meat, then it can be Portugese stew", in which case not-A and B is ok in the first case but not the second) and also temporal relations (e.g. "if she put the book on the shelf, then it fell off").

## Abduction

Abduction is the idea of going beyond just inference (i.e. concluding something beyond the information given) to actually inferring a theory or explanation for the conclusions. For example, when asked "If the trigger is pulled, then the pistol will fire. The trigger is pulled, but the pistol does not fire. Why not?", people seem to augment their mental models in order to find a set of premises that does make the conclusions valid, such as that there were no bullets in the pistol.

# Takeaways

I spent a long time thinking about the illusory inferences, and I'm dissatisfied with the explanation. Here is an example of one, where only one of the propositions is true:

> If there is a king then there is an ace or else if there isn't a king then there is an ace.
> There is a king.
> What follows?

People invariably say "there is an ace", but this is technically incorrect. The reason is that the way this is supposed to be parsed is something like this:

    P1: king --> ace
    P2: not king --> ace
    P1 xor P2
    king

Because only one of P1 or P2 can be true, that means if P1 were false then `king --> not ace` and therefore "there is an ace" is not a valid conclusion. Johnson-Laird claims this is based on how people construct their mental models, but I think it has more to do with the language of the scenario. When I write it out as I did just above, the answer is much more obviousâ€”it took me a long time to realize why it was obvious because I was actually parsing the entire situation incorrectly. Perhaps it is just my programming background, but I intuitively parsed this statement into a program like this:

    king = True
    if king:
        ace = True
    elif not king:
        ace = True

Clearly, at the end of execution, `ace` will be true. I think the effect would be much lessened if instead the problem were given like:

> There are two rules, only one of which is true: (1) a king implies an ace, or (2) lack of a king implies an ace.
> There is a king.
> What follows?

An informal test of $n=1$ suggests this is a better phrasing, as they correctly determined that there is nothing you can deduce here. Looking it up, I see that Johnson-Laird did test for exactly this in [Experiment 2 of this paper](http://mentalmodels.princeton.edu/papers/1999illusory.pdf). They did find that more people got the correct answer when they changed the language (25% vs 0%), though the majority still made the error.
