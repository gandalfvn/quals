<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Quals Reading Notes</title>
    <description>Notes on readings for my qualifying exams.
</description>
    <link>http://jhamrick.github.io/quals/</link>
    <atom:link href="http://jhamrick.github.io/quals/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 14 Jan 2016 15:04:09 -0800</pubDate>
    <lastBuildDate>Thu, 14 Jan 2016 15:04:09 -0800</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>Evaluation of real-time physics simulation systems</title>
        <description>&lt;p&gt;&lt;span id=&quot;Boeing2007&quot;&gt;Boeing, A., &amp;amp; Bräunl, T. (2007). Evaluation of real-time physics simulation systems. &lt;i&gt;Proceedings Of the 5th International Conference on Computer Graphics and Interactive Techniques in Australia and Southeast Asia&lt;/i&gt;, &lt;i&gt;1&lt;/i&gt;(212). doi:10.1145/1321261.1321312&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper Boeing &amp;amp; Bräunl evaluate and compare a number of game physics engines. They do this through the Physics Abstraction Layer (PAL), which is a common layer for multiple physics engines developed by the first author. They perform a number of tests:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Integrator test&lt;/strong&gt; — looking at the integrator error. All of them have some error because they are by definition approximations.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bounce height test&lt;/strong&gt; — looking at how high a ball bounces based on different coefficients of restitution. Most of the engines have behavior that depends on the restitution, though some (e.g. ODE) don’t because they resolve collisions using repulsive forces rather than impulse based methods (which conserve momentum)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Friction test&lt;/strong&gt; — looking at what angle a box starts moving on an incline plane as a function of the coefficient of friction. There is significant variability here, though all engines require a larger angle for larger coefficients.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Constraint stability test&lt;/strong&gt; — looking at how stable constraints are (i.e. whether they allow objects to drift apart or not). For all engines the error increased as a function of the number constraints (linked together in a chain).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Collision test&lt;/strong&gt; — looking at whether objects pass through each other after a collision, and how much interpenetration error there is. Several engines failed this test, allowing objects to pass through. Bullet was the only engine to converge on zero interpenetration error, though with larger time steps Bullet also failed the test.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stacking test with boxes&lt;/strong&gt; — looking at whether a stack of boxes should fall over, inspected visually. All engines passed.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stacking test with spheres&lt;/strong&gt; — looking at whether a stack of spheres should fall over, inspected visually. All engines failed (the spheres stayed stacked on top of each other)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;It’s a little hard to interpret these results since all the physics engines can be tweaked in various ways depending on what you want them to do. Also, the last test—stacking with spheres—seems a bit weird to me. Physically, the results they got are accurate; the authors complained that the engines should have added noise in order to make the scenario realistic. I disagree: for a physics engine, you want reproducible results. If, as a programmer, you want the engine to incorporate noise you can add it yourself. It’s not even clear here what source of noise they would prefer the engines to implement. (Positional noise? Small random perturbations?)&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Jan 2016 06:37:28 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/physically-based%20animation/2016/01/14/Boeing2007.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/physically-based%20animation/2016/01/14/Boeing2007.html</guid>
        
        
        <category>Physically-based animation</category>
        
      </item>
    
      <item>
        <title>Physically based deformable models in computer graphics</title>
        <description>&lt;p&gt;&lt;span id=&quot;Nealen2006&quot;&gt;Nealen, A., Müller, M., Keiser, R., Boxerman, E., &amp;amp; Carlson, M. (2006). Physically based deformable models in computer graphics. &lt;i&gt;Computer Graphics Forum&lt;/i&gt;, &lt;i&gt;25&lt;/i&gt;(4), 809–836. doi:10.1111/j.1467-8659.2006.01000.x&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;This is a review paper which gives an overview of some of the techniques that have been used to model deformable objects, including cloth, deformable volumes, and fluids. The major division between methods is whether the method is &lt;em&gt;Eulerian&lt;/em&gt; or &lt;em&gt;Lagrangian&lt;/em&gt;. Lagrangian methods directly model particles or meshes that are subject to forces, and then update the positions/velocities of those particles/meshes. Eulerian methods, in contrast, directly model the velocity field at each point. As they describe it:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[T]he Lagrangian point of view describes an object as a set of moving points (material coordinates) that travel around and change position over time; these points carry their material properties with them as they move through the world. The Eulerian point of view, on the other hand, looks at a stationary est of points and calculates how the material properties stored at those stationary grid points changes over time. (Sec. 6)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The benefit of Lagrangian methods is that it is easy to define a surface boundary for the material. However, in the case of fluids, Eulerian methods are preferred because they ensure velocities are incompressible and thus divergence free.&lt;/p&gt;

&lt;p&gt;Many of the techniques in the paper either use &lt;em&gt;implicit&lt;/em&gt; or &lt;em&gt;explicit&lt;/em&gt; time integration schemes. Explicit schemes involve an explicit equation for the quantity at the next time step. Implicit schemes have terms for the quantity of the next time step on both sides of the equation, thus implicitly defining the value as the solution to a system of equations.&lt;/p&gt;

&lt;h2 id=&quot;lagrangian-methods&quot;&gt;Lagrangian Methods&lt;/h2&gt;

&lt;p&gt;Lagrangian methods can either be applied to mesh-based models or mesh-free models.&lt;/p&gt;

&lt;h3 id=&quot;mesh-based-models&quot;&gt;Mesh-based models&lt;/h3&gt;

&lt;p&gt;For mesh-based models, the two common approaches are either &lt;em&gt;continuum&lt;/em&gt; methods or &lt;em&gt;mass-spring systems&lt;/em&gt;. Continuum methods assume a continous object and then discretize the PDE describing the behavior of that object. Mass-spring systems assume a discrete object to begin with (i.e., a lattice of point masses connected by springs). There are a number of variants of continuum methods which differ based on the method of discretization:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Finite Element Method&lt;/strong&gt; — discretization occurs using an irregular mesh. In the &lt;em&gt;explicit FEM&lt;/em&gt; method, the masses and internal/external foces are lumped into the vertices of the mesh and then the mesh is treated like a mass-spring system. Also, as described in &lt;a href=&quot;/quals/physically-based%20animation/2016/01/13/Mueller2002.html&quot;&gt;Müller et al.&lt;/a&gt;, when using implicit time integration with FEM, the resulting system of equations is linear, thus introducing artifacts, and additional processing must be done in order to account for these.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Method of Finite Differences&lt;/strong&gt; — discretization occurs using a regular mesh. However, this is difficult to achieve when objects have irregular edges.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Finite Volume Method&lt;/strong&gt; — forces are computed by integrating over the face of a finite element, rather than the entire volume of the element (this name seems counterintuitive?)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Boundary Element Method&lt;/strong&gt; — computations are done on the surface of the object, rather than its volume. This only works for homogenous materials, though.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While continuum methods are usually used for deformable solid objects, mass-spring systems are more frequently used for cloth.&lt;/p&gt;

&lt;h3 id=&quot;mesh-free-models&quot;&gt;Mesh-free models&lt;/h3&gt;

&lt;p&gt;Mesh-free models tend to be used for fluids and fuzzy objects, e.g. fire, clouds, water, etc.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Loosely coupled particle systems&lt;/strong&gt; — particles are points in 3D space which define the volume of an object and particles interact pairwise with each other. Depending on the parameters of the potential function, particles can be used to model a range of behaviors from something very stiff to fluid-like. To define the surface of the volume, each particle is assigned a Gaussian potential and then these potentials are summed to form a continuous field in space which defines where the boundary is (this is known as &lt;em&gt;coating&lt;/em&gt;).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Smoothed particle hydrodynamics (SPH)&lt;/strong&gt; — another particle method (described by &lt;a href=&quot;/quals/physically-based%20animation/2016/01/14/Mueller2003.html&quot;&gt;Müller et al.&lt;/a&gt;) where instead of having pairwise interactions, the forces are derived from Navier-Stokes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Point-based animations&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Meshless deformations based on shape matching&lt;/strong&gt; — vertices of a mesh are animated as a particle system, and then correspondences are found between the original mesh and the particles. Points are pulled back to their original positions, allowing the object to recover from severe deformations.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;eulerian-methods&quot;&gt;Eulerian Methods&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;/quals/physically-based%20animation/2016/01/12/Stam1999.html&quot;&gt;Stam&lt;/a&gt; describes a Eulerian method for fluid simulation which uses the &lt;em&gt;semi-Lagrange&lt;/em&gt; technique for advection. Other Eulerian techniques have been developed to include temperature and variable viscosity (enabling melting) and also elasticity (allowing for viscoelastic substances). The surface of the fluid can be computed using &lt;em&gt;level sets&lt;/em&gt;, which store the signed distance to the surface of the fluid and which are then updated on each step of the simulation based on the velocity field.&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Jan 2016 05:02:36 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/physically-based%20animation/2016/01/14/Nealen2006.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/physically-based%20animation/2016/01/14/Nealen2006.html</guid>
        
        
        <category>Physically-based animation</category>
        
      </item>
    
      <item>
        <title>Particle-based fluid simulation for interactive applications</title>
        <description>&lt;p&gt;&lt;span id=&quot;Muller2003&quot;&gt;Müller, M., Charypar, D., &amp;amp; Gross, M. (2003). Particle-Based Fluid Simulation for Interactive Applications. &lt;i&gt;Proceedings Of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation&lt;/i&gt;, 154–159. Retrieved from http://dl.acm.org/citation.cfm?id=846298&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Müller et al. describe a method for online simulation of fluids with free surfaces (i.e., liquids rather than gases) based on &lt;em&gt;smooth particle hydrodynamics&lt;/em&gt; (SPH). SPH is essentially just an interpolation equation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A_S(\mathbf{r})=\sum_j m_j\frac{A_j}{\rho_j}W(\mathbf{r}-\mathbf{r}_j,h)&lt;/script&gt;

&lt;p&gt;where $A$ is the quantity being interpolated and $\mathbf{r}$ is the location of interest. The variables $m_j$, $\rho_j$, and $\mathbf{r}_j$ are the mass, density, and position of the $j$th particle, respectively. The function $W(\mathbf{r},h)$ is the smoothing kernel with radius $h$ that integrates to 1. In this paper, they use three different smoothing kernels, $W_\mathrm{poly6}$, $W_\mathrm{spiky}$, and $W_\mathrm{viscosity}$.&lt;/p&gt;

&lt;p&gt;To apply SPH to fluid simulation, Müller begin with a modified version of Navier-Stokes for particle systems (which excludes a convective term because it is not needed for particles which move with the fluid):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\rho\frac{D\mathbf{v}}{D t}&amp;=-\nabla p+\rho\mathbf{g}+\mu\nabla^2\mathbf{v}\\
&amp;=\mathbf{f}^\mathrm{pressure}+\mathbf{f}^\mathrm{external}+\mathbf{f}^\mathrm{viscosity}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where $\mathbf{v}$ is the velocity field, $\rho$ is the density field, $p$ is the pressure field, $\mathbf{g}$ is an external force density field, and $\mu$ is the viscosity of the fluid. They compute the density field using SPH:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\rho_S(\mathbf{r})=\sum_j m_j W_\mathrm{poly6}(\mathbf{r}-\mathbf{r}_j,h)&lt;/script&gt;

&lt;p&gt;Then, they define the force density terms separately also using SPH. For the pressure term:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{f}_i^\mathrm{pressure}=-\sum_j m_j\frac{p_i+p_j}{2\rho_j}\nabla W_\mathrm{spiky}(\mathbf{r}_i-\mathbf{r}_j,h)&lt;/script&gt;

&lt;p&gt;which uses the mean of the pressures of interacting particles. The pressure is computed as $p=k(\rho-\rho_0)$, where $k$ is a gas constant that depends on temperature, and where $\rho_0$ the rest density.&lt;/p&gt;

&lt;p&gt;The external force density term is applied directly to the particles and does not involve SPH.&lt;/p&gt;

&lt;p&gt;The viscosity term is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{f}_i^\mathrm{viscosity}=\mu\sum_j m_j\frac{\mathbf{v}_j-\mathbf{v}_i}{\rho_j}\nabla^2 W_\mathrm{viscosity}(\mathbf{r}_i-\mathbf{r}_j,h)&lt;/script&gt;

&lt;p&gt;which uses the difference in velocity between the two particles.&lt;/p&gt;

&lt;p&gt;They additional define a surface tension force density:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{f}^\mathrm{surface}=-\sigma\nabla^2 c_S\frac{\mathbf{n}}{\vert\mathbf{n}\vert}&lt;/script&gt;

&lt;p&gt;where $\sigma$ is a tension coefficient, $c_S$ is a &lt;em&gt;color field&lt;/em&gt; and $\mathbf{n}$ is the gradient of the color field. A color field is 1 at particle locations and 0 everywhere else. Interpolating it with SPH gives:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;c_S(\mathbf{r})=\sum_j m_j\frac{1}{\rho_j}W_\mathrm{poly6}(\mathbf{r}-\mathbf{r}_j,h)&lt;/script&gt;
</description>
        <pubDate>Thu, 14 Jan 2016 03:19:26 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/physically-based%20animation/2016/01/14/Mueller2003.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/physically-based%20animation/2016/01/14/Mueller2003.html</guid>
        
        
        <category>Physically-based animation</category>
        
      </item>
    
      <item>
        <title>Simulation of clothing with folds and wrinkles</title>
        <description>&lt;p&gt;&lt;span id=&quot;Bridson2003&quot;&gt;Bridson, R., Marino, S., &amp;amp; Fedkiw, R. (2003). Simulation of clothing with folds and wrinkles. &lt;i&gt;Proceedings Of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation&lt;/i&gt;, 28–36. Retrieved from http://dl.acm.org/citation.cfm?id=846281&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Bridson et al. propose a method for simulating clothing while preserving folds and wrinkles. They propose a mixed implicit/explicit time integration method, derive a physically accurate bending model, and handle interpenetrations in a way that preserves wrinkles.&lt;/p&gt;

&lt;p&gt;In the time integration method, they use an implicit method for the cloth’s velocity-dependent forces (damping forces) and explicit methods for velocity-independent forces (elastic forces). Because the implicit method introduces damping, it is appropriate for the damping forces; however, when applied to the elastic forces, it results in too much damping and doesn’t handle nonlinearities in the elastic forces well.&lt;/p&gt;

&lt;p&gt;The bending model considers the bend between two triangles in a mesh which share an edge. There are four vertices $x_i$ between the two triangles, each with an associated velocity $v_i$ and force $F_i$. The normals of the triangles are $n_1$ and $n_2$ and the angle between them is $\theta$. The velocities and forces make up a 12-dimensional space. Rather than directly using this space, Bridson et al. come up with a basis for the space which consists of: 3 rigid body translations, three rigid body rotations, two in-plane motions of vertex 1, two in-plane motions of vertex 2, one in-line stretching of edge 3-4, and the change in $\theta$ (the “bending mode”). The bending mode is orthogonal to all the other modes and is denoted $u=(u_1,u_2,u_3,u_4)$. Based on the condition of orthogonality, they derive values for each $u_i$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
u_1&amp;=\vert E\vert \frac{N_1}{\vert N_1\vert^2}\\
u_2&amp;=\vert E\vert \frac{N_2}{\vert N_2\vert^2}\\
u_3&amp;=\frac{(x_1-x_4)\cdot{}E}{\vert E\vert}\frac{N_1}{\vert N_1\vert^2}+\frac{(x_2-x_4)\cdot{}E}{\vert E\vert}\frac{N_2}{\vert N_2 \vert^2}\\
u_4&amp;=\frac{(x_1-x_3)\cdot{}E}{\vert E\vert}\frac{N_1}{\vert N_1\vert^2}+\frac{(x_2-x_3)\cdot{}E}{\vert E\vert}\frac{N_2}{\vert N_2 \vert^2}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where $N_1=(x_1-x_3)\times (x_1-x_4)$ and $N_2=(x_2-x_4)\times(x_2-x_3)$ are the area weighted normals and $E=x_4-x_3$ is the common edge. Because $u$ is orthogonal to all the other modes of motion, the forces related to bending—the elastic bending force and the damping bending force—must be proportional to $u$ in order to preserve orthogonality. For the elastic force they use:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F_i^e=k^e\frac{\vert E\vert^2}{\vert N_1\vert+\vert N_2\vert}\left(\sin(\theta/2)-\sin(\theta_0/2)\right)u_i&lt;/script&gt;

&lt;p&gt;where $k^e$ is a material property (the elastic bending stiffness) and $\theta_0$ is the &lt;em&gt;rest angle&lt;/em&gt;, which can be used to enforce that the cloth bends in a particular way. For the damping force they use:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F_i^d=-k^d\vert E\vert (d\theta/dt)u_i&lt;/script&gt;

&lt;p&gt;where $k^d$ is a material property.&lt;/p&gt;

&lt;p&gt;To resolve interpentrations, rather than projecting the interpenetrating material onto the surface of the mesh (which causes wrinkles to be flattened out), they project the interpenetrating material into an interval $[0,\tau]$. This means that wrinkles may not be as peaked as they were (as they may only be peaked up to a height of $\tau$), but this will preserve the contours of the folds at least.&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Jan 2016 02:09:22 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/physically-based%20animation/2016/01/14/Bridson2003.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/physically-based%20animation/2016/01/14/Bridson2003.html</guid>
        
        
        <category>Physically-based animation</category>
        
      </item>
    
      <item>
        <title>Nonconvex rigid bodies with stacking</title>
        <description>&lt;p&gt;&lt;span id=&quot;Guendelman2003&quot;&gt;Guendelman, E., Bridson, R., &amp;amp; Fedkiw, R. (2003). Nonconvex Rigid Bodies with Stacking. &lt;i&gt;ACM Transactions On Graphics&lt;/i&gt;, &lt;i&gt;22&lt;/i&gt;(3). doi:10.1145/882262.882358&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Guendelman et al. propose a method for detecting and resolving collisions when dealing with nonconvex rigid bodies, particularly in scenarios when those bodies need to stack. There are three main pieces to their approach: the geometric representation, the time integration method, and a &lt;em&gt;shock propagation&lt;/em&gt; method for propagation-based contact resolution.&lt;/p&gt;

&lt;p&gt;First, the geometric representation that they use is the typical triangular mesh, plus a &lt;em&gt;signed distance function&lt;/em&gt;, which gives the distance to the (closest) surface of the mesh along the normal vector. Distances inside the mesh are negative, and distances outside the mesh are positive. Such a distance function makes it easy to detect collisions because for a given vertex, you can check what the distance is relative to another object. If the distance is negative, then you know that the objects are interpenetrating.&lt;/p&gt;

&lt;p&gt;Second, the time integration method that they use has four components:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Detect and resolve collisions&lt;/li&gt;
  &lt;li&gt;Update object velocities&lt;/li&gt;
  &lt;li&gt;Detect and resolve contacts&lt;/li&gt;
  &lt;li&gt;Update object positions&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;By performing the steps in this order, this method avoids issues with undesirable behavior when friction is high (and therefore objects shouldn’t move). They give the example of a block on an inclined plane:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Consider a block sitting still on an inclined plane with a large coefficient of restitution, say $\epsilon=1$, and suppose that friction is large enough that the block should sit still. In a standard time stepping scheme, both position and velocity are updated first, followed by collision and contact resolution. During the position and velocity update, the block starts to fall under the effects of gravity. Then in the collision processing stage we detect a low velocity collision between the block and the plane, and since $\epsilon=1$ the block will change direction and bounce upwards at an angle down the incline. Then in the contact resolution stage, the block and the plane are separating so nothing happens. The block will eventually fall back to the inclined plane, and continue bouncing up and down incorrectly sliding down the inclined plane because of the time it spends in the ballistic phase.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;They use a propagation method for resolving collisions, in which they predict where the objects will be, temporarily move them there, and then check for collisions and process them. This might result in new collisions, so they repeat the process a number of times (5). The method for resolving contacts is similar, except that they additionally use a &lt;em&gt;contact graph&lt;/em&gt; which reflects which objects are resting on which. They separate the graph into levels such that the objects in level $i$ are lower than the objects in level $i+1$, and then process the levels sequentially.&lt;/p&gt;

&lt;p&gt;Finally, after several iterations of contact resolution, they use a method called &lt;em&gt;shock propagation&lt;/em&gt;. In this method, they process the contacts at level $i$ and then temporarily fix the positions of those objects (zero the velocity and give them infinite mass). Then, when they process the contacts at level $i+1$, those objects cannot affect the objects at level $i$ and so therefore the contact resolution is propagated upward.&lt;/p&gt;
</description>
        <pubDate>Wed, 13 Jan 2016 14:56:20 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/physically-based%20animation/2016/01/13/Guendelman2003.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/physically-based%20animation/2016/01/13/Guendelman2003.html</guid>
        
        
        <category>Physically-based animation</category>
        
      </item>
    
      <item>
        <title>Stable real-time deformations</title>
        <description>&lt;p&gt;&lt;span id=&quot;Muller2002&quot;&gt;Müller, M., Dorsey, J., &amp;amp; McMillan, L. (2002). Stable Real-time Deformations. &lt;i&gt;Proceedings Of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation&lt;/i&gt;. doi:10.1145/545261.545269&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Müller et al. introduce a stable method for deforming objects without increasing the volume of the object.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;Finite Element Method&lt;/em&gt; gives a function $F$ that converts deformations into elastic forces:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{f}_\mathrm{elastic}=F(\mathbf{x}-\mathbf{x}_0)&lt;/script&gt;

&lt;p&gt;where $\mathbf{x}$ is the deformed location of the element and $\mathbf{x}_0$ is the original location of the element. The Jacobian of this matrix evaluated at $\mathbf{x}_0$ is called the &lt;em&gt;stiffness matrix&lt;/em&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;K=\frac{\partial F}{\partial\mathbf{x}}(\mathbf{x}_0)&lt;/script&gt;

&lt;p&gt;In the linear case, $F$ is approximated by a first-order approximation, giving&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{f}_\mathrm{elastic}=K\cdot(\mathbf{x}-\mathbf{x}_0)&lt;/script&gt;

&lt;p&gt;However, this assumes that the transformation between $\mathbf{x}_0$ and $\mathbf{x}$ is linear (i.e., no rotations). If this assumption is violated, because linear elastic forces are invariant under translations but not rotations, the resulting simulation will over-stretch.&lt;/p&gt;

&lt;p&gt;To avoid this, Müller compute the forces in the original (unrotated) coordinate frame and then transform them back into the rotated coordinate frame:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{f}_\mathrm{elastic}=R_eK\cdot{}(R_e^{-1}\mathbf{x}-\mathbf{x}_0)&lt;/script&gt;

&lt;p&gt;where $R_e$ is a block matrix with the gobal rotation matrix $R_x$ repeated four times along the diagonal and zeros everywhere else (repeated once for each vertex). From this, they compute the force for the whole mesh by &lt;em&gt;warping&lt;/em&gt; the stiffness matrix according to the rotation of each vertex. The force at vertex $i$ is then:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{f}_i=R_i\sum_{j=1}^n k_{ij}(R_i^{-1}\mathbf{x}_j-\mathbf{x}_{0j})&lt;/script&gt;

&lt;p&gt;where $R_i$ is the rotation matrix for vertex $i$. However, these &lt;em&gt;local&lt;/em&gt; rotations aren’t known (the global rigid-body rotation is known, but we want to know the local rotations which include the effect of deformation). Given the vectors for the original mesh ($\mathbf{u}$), and the vectors of the deformed/rotated mesh ($\mathbf{v}$), they compute:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F_{ij}=\sum_{k=1}^N (\mathbf{n}_i\cdot{}\mathbf{u}_k)(\mathbf{n}_j\cdot{}\mathbf{v}_k)&lt;/script&gt;

&lt;p&gt;where $\mathbf{n}_1$, $\mathbf{n}_2$, and $\mathbf{n}_3$ are the basis vectors of $\mathbb{R}^3$. Given $F$, they decompose it using SVD to get $F=USV^\top$, and then compute the rotation matrix as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R=VU^\top&lt;/script&gt;
</description>
        <pubDate>Wed, 13 Jan 2016 11:30:33 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/physically-based%20animation/2016/01/13/Mueller2002.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/physically-based%20animation/2016/01/13/Mueller2002.html</guid>
        
        
        <category>Physically-based animation</category>
        
      </item>
    
      <item>
        <title>Stable fluids</title>
        <description>&lt;p&gt;&lt;span id=&quot;Stam1999&quot;&gt;Stam, J. (1999). Stable Fluids. &lt;i&gt;Proceedings Of the 26th Annual Conference on Computer Graphics and Interactive Techniques&lt;/i&gt;. doi:10.1145/311535.311548&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;This paper introduces the first stable fluid simulation algorithm for computer graphics. This is a hard problem, because there is not analytic solution to Navier-Stokes. Previous methods had used explicit approximations such as Eulerian methods; however, these types of methods can become unstable and “blow up” for large timesteps. Using small enough timesteps is not a feasible option in computer graphics, in which the simulation needs to run in real time, thus prohibiting small timesteps.&lt;/p&gt;

&lt;p&gt;This algorithm is specific to contained fluids (i.e., gases) and approximates the following form of Navier-Stokes:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \mathbf{u}}{\partial t}=\mathbf{P}\left(-(\mathbf{u}\cdot{}\nabla)\mathbf{u}+\nu\nabla^2\mathbf{u}+\mathbf{f}\right)&lt;/script&gt;

&lt;p&gt;where $\nabla\cdot{}\mathbf{u}=0$. Here, $\mathbf{u}$ is the velocity field, $\nabla$ is a vector of spatial partial derivatives, $\nu$ is the kinematic viscosity of the fluid, $\mathbf{f}$ is an external force, and $\mathbf{P}$ is a projection operator which projects any vector field onto its &lt;em&gt;divergence free&lt;/em&gt; part. Divergence free essentially means that at any point in the vector field, the flow towards that point is the same as the flow away from it.&lt;/p&gt;

&lt;p&gt;They compute the approximate solution to this equation in four steps. First, $\mathbf{w}_0$ is the solution from the previous time step:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{w}_0(\mathbf{x})=\mathbf{u}(\mathbf{x},t)&lt;/script&gt;

&lt;p&gt;Then, the first step is to &lt;em&gt;add force&lt;/em&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{w}_1(\mathbf{x})=\mathbf{w}_0+\Delta t\ \mathbf{f}(\mathbf{x},t)&lt;/script&gt;

&lt;p&gt;The second step is &lt;em&gt;advection&lt;/em&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{w}_2(\mathbf{x})=\mathbf{w}_1(\mathbf{p}(\mathbf{x},-\Delta t))&lt;/script&gt;

&lt;p&gt;where $\mathbf{p}(\mathbf{x},-\Delta t)$ says that the new velocity at $\mathbf{x}$ is the velocity at a location backwards in time by $-\Delta t$ (i.e., something like the velocity at the location given by $\dot{\mathbf{x}}\ \Delta t)$.&lt;/p&gt;

&lt;p&gt;The third step is &lt;em&gt;diffusion&lt;/em&gt;, in which the effects of viscosity are applied and solved as a linear system:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left(\mathbf{I}-\nu\Delta t\nabla^2\right)\mathbf{w}_3(\mathbf{x})=\mathbf{w}_2(\mathbf{x})&lt;/script&gt;

&lt;p&gt;The fourth and final step is &lt;em&gt;projection&lt;/em&gt;, in which the system is projected back onto its divergence free part.&lt;/p&gt;
</description>
        <pubDate>Tue, 12 Jan 2016 07:53:39 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/physically-based%20animation/2016/01/12/Stam1999.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/physically-based%20animation/2016/01/12/Stam1999.html</guid>
        
        
        <category>Physically-based animation</category>
        
      </item>
    
      <item>
        <title>Rational use of cognitive resources: levels of analysis between the computational and the algorithmic</title>
        <description>&lt;p&gt;&lt;span id=&quot;Griffiths2015&quot;&gt;Griffiths, T. L., Lieder, F., &amp;amp; Goodman, N. D. (2015). Rational Use of Cognitive Resources: Levels of Analysis Between the Computational and the Algorithmic. &lt;i&gt;Topics In Cognitive Science&lt;/i&gt;, &lt;i&gt;7&lt;/i&gt;(2), 217–229. doi:10.1111/tops.12142&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Griffiths et al. propose a focus on levels between the computational and algorithmic. They outline a method for approaching analysis at these intermediate levels called &lt;em&gt;resource-rational analysis&lt;/em&gt;. The key idea in resource-rational analysis is to begin with a computational-level analysis, assume an idealized &lt;em&gt;abstract computational architecture&lt;/em&gt; that solves the proplem posed at the computational level, and then examine how resources should be used optimally within that framework. It is specifically &lt;em&gt;not&lt;/em&gt; a proposal to modify the computational level:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Rather than blurring these lines and building constraints into computational-level theories, we suggest a different approach: define the computational-level theory without considering limitations on its execution, and then explore the consequences of those limitations as a further analysis that brings us closer to an algorithmic-level theory… Various proposals about limitations—or alternatively abstract computational architectures—provide us with levels of analysis between the computational and the algorithmic, and the principle of rationality provides us with a methodology for developing models at those intermediate levels. (pg. 220)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Griffiths et al. outline four steps in performing a resource-rational analysis:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Function&lt;/strong&gt;. Perform a computational-level analysis to determine the function of the system.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Model of mental computation&lt;/strong&gt;. Pick a class of algorithms that approximate the optimal solution (e.g. particle filters), and define what the costs are in the model (e.g. number of samples).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Optimal resource allocation&lt;/strong&gt;. Determine which algorithm should be used in order to optimally trade off between accuracy and computational cost (i.e., be “resource rational”)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Evaluate and refine&lt;/strong&gt;. Compare to human behavior, and revise assumptions in steps 1, 2, and 3 as necessary.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;They posit a very specific definition of resource rationality, based on the notion of &lt;em&gt;value of computation&lt;/em&gt; (VOC), defined as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
c^*&amp;=\mathrm{arg}\max_{c\in C^n}\mathrm{VOC}(c)\\
\mathrm{VOC}(c)&amp;=\mathbb{E}_{P(B\vert c)}\left[\max_a \mathbb{E}_{P(Q,s\vert B)}[Q(s, a)]\right] - \mathrm{cost}(c)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where $c$ is a computation, $s$ is the state, $a$ is the action, $Q(s,a)$ is the $Q$ function, and $B$ is the agent’s belief about $Q$ and $s$.&lt;/p&gt;

&lt;p&gt;Griffiths et al. note that in many cases, the initial resource-rational analysis may start by making certain assumptions of unbounded optimality (e.g., the ability to take perfect posterior samples). Further iterations of the analysis can identify these assumptions and apply a resource-rational analysis to them as well (e.g., correlated MCMC samples).&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;I like this approach a lot, and I think that starting with approximation algorithms from computer science is likely to be incredibly fruitful. However, a lot of the algorithms from computer science have proven bounds for large $n$. I wonder to what extent there are other algorithms that computer scientists aren’t necessarily investigating that have provably better bounds (or other relevant properties) for small $n$? For example, are there inference algorithms that do poorly in terms of getting perfect posterior samples as $n$ goes to infinity, but which perhaps give somewhat better samples (e.g. less correlated) in the short term than more popular algorithms like MH?&lt;/p&gt;
</description>
        <pubDate>Tue, 12 Jan 2016 07:53:39 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/rational%20process%20models/2016/01/12/Griffiths2015.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/rational%20process%20models/2016/01/12/Griffiths2015.html</guid>
        
        
        <category>Rational process models</category>
        
      </item>
    
      <item>
        <title>Selecting computations: theory and applications</title>
        <description>&lt;p&gt;&lt;span id=&quot;Hay2012&quot;&gt;Hay, N. J., Russell, S. J., Tolpin, D., &amp;amp; Shimony, S. E. (2012). Selecting Computations: Theory and Applications. &lt;i&gt;ArXiv Preprint ArXiv:1207.5878v1 [Cs.AI]&lt;/i&gt;. Retrieved from http://arxiv.org/abs/1207.5879&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;This paper is quite related to &lt;a href=&quot;/quals/planning%20and%20decision%20making/2015/12/19/Guez2013.html&quot;&gt;Guez et al.&lt;/a&gt;, &lt;a href=&quot;/quals/planning%20and%20decision%20making/2015/12/16/Browne2012.html&quot;&gt;Browne et al.&lt;/a&gt;, and &lt;a href=&quot;/quals/planning%20under%20uncertain%20dynamics/2015/12/30/Bertuccelli2012.html&quot;&gt;Bertuccelli et al.&lt;/a&gt;. Here, Hay et al. suggest that to optimally make use of information earned when exploring a state/action space, a &lt;em&gt;metalevel&lt;/em&gt; decision problem needs to be solved:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Exploring unpromising or highly predictable paths to great depth is often wasteful; for a given amount of exploration, decision quality can be improved by directing exploration towards those actions sequences whose outcomes are helpful in selecting a good move. Thus, the &lt;em&gt;metalevel&lt;/em&gt; decision problem is to choose what future action sequences to explore (or, more generally, what deliberative computations to do), while the &lt;em&gt;object-level&lt;/em&gt; decision problem is to choose an action to execute in the real world. (pg. 1)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;They show that the UCB1 or UCT bounds (used in bandit problems and MCTS) are suboptimal for the metalevel decision problem. The difference, they say, is that in bandit problems, the decision is relative to a utility you get in the real world, but in metalevel problems, the decision is relative to a cost of computation of &lt;em&gt;simulations&lt;/em&gt; rather than real-world actions.&lt;/p&gt;

&lt;p&gt;In some cases, the prior distribution of real-world outcomes is known and can be used in the simulations. However, in many other cases, the prior distribution on utilities is not available. Instead, the VOI (value of information) can be used as a way of determining what actions are good to take. These VOIs cannot be computed exactly, but under a few assumptions (myopic policy, samples are iid, expectation of a selection is equal to the sample mean, the distribution is bounded on both sides), they can be bounded from above. Hay et al. prove this bound, and show how it can be applied to MCTS: for root node sampling, rather than following the UCT policy, they use the VOI policy.&lt;/p&gt;

&lt;h1 id=&quot;methods&quot;&gt;Methods&lt;/h1&gt;

&lt;p&gt;n/a&lt;/p&gt;

&lt;h1 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h1&gt;

&lt;p&gt;A &lt;em&gt;metalevel decision process&lt;/em&gt; is denoted $M=(S,s_0,A_s,T,R)$, where $S$ are the states, $s_0$ is the intitial state, $A_s$ is the set of actions which includes simulated actions $E\in\mathcal{E}$ as well as the “stop” action $\perp$, $T$ is the transition function, and $R$ is the reward function, such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
T(s,E,s^\prime)&amp;=p(E=e\ \vert\ E_1=e_1,\ldots{},E_n=e_n)\\
T(s,\perp,\perp)&amp;=1\\
R(s,E,s^\prime)&amp;=-c\\
R(s,\perp,\perp)&amp;=\max_i\mu_i(s)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where $\mu_i(s)=\mathbb{E}[U_i\ \vert\ E_1=e_1,\ldots{},E_n=e_n]$. The value function of a policy $\pi$ for this MDP is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;V_M^\pi(s)=\mathbb{E}_M^\pi[-cN+\max_i\mu_i(S_N)\ \vert\ S_0=s]&lt;/script&gt;

&lt;p&gt;where $N$ is the total number of computations performed. The &lt;em&gt;expected&lt;/em&gt; number of computations is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E^{\pi^*}[N\ \vert\ S_0=s]\leq \frac{1}{c}\left(\mathbb{E}[\max_i U_i\ \vert\ S_0=s]-\max_i\mu_i(s)\right)&lt;/script&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;It would be interesting to see how this integrates with the Bayes-adaptive MCTS from &lt;a href=&quot;/quals/planning%20and%20decision%20making/2015/12/19/Guez2013.html&quot;&gt;Guez et al.&lt;/a&gt;. There, not only do they run simulations starting from the root node, they also resample the MDP from the prior distribution. So, I’m not sure whether the VOI approach here would still hold in that case. In general though, I do think it is important to take the metalevel decision making problem into account, so this is a really interesting direction to pursue particularly in the context of human reasoning (where our brains almost certainly need to make tradeoffs between doing more computation and acting).&lt;/p&gt;
</description>
        <pubDate>Tue, 12 Jan 2016 05:15:18 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/rational%20process%20models/2016/01/12/Hay2012.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/rational%20process%20models/2016/01/12/Hay2012.html</guid>
        
        
        <category>Rational process models</category>
        
      </item>
    
      <item>
        <title>Bayesian fundamentalism or enlightenment? On the explanatory status and theoretical contributions of Bayesian models of cognition</title>
        <description>&lt;p&gt;&lt;span id=&quot;Jones2011&quot;&gt;Jones, M., &amp;amp; Love, B. C. (2011). Bayesian fundamentalism or enlightenment? On the explanatory status and theoretical contributions of Bayesian models of cognition. &lt;i&gt;The Behavioral And Brain Sciences&lt;/i&gt;, &lt;i&gt;34&lt;/i&gt;(4), 169–188. doi:10.1017/S0140525X10003134&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;Jones &amp;amp; Love critique the use of Bayesian models of cognition, contrasting &lt;em&gt;Bayesian Fundamentalism&lt;/em&gt;, which:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;… adheres to the tenet that human behavior can be explained through rational analysis — once the correct probabilistic interpretation of the task environment has been identified — without recourse to process, representation, resource limitations, or physiological or developmental data. (pg. 170)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;with &lt;em&gt;Bayesian Enlightenment&lt;/em&gt;, which:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;… goes beyond the dogma of pure rational analysis and actively attemps to integrate with other avenues of inquiry in cognitive science… [it] thus treats Bayesian models as making both rational and mechanistic commitments, and it takes as a goal the joint evaluation of both. (pg. 170)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Jones &amp;amp; Love compare Bayesian Fundamentalism to Behaviorism and Evolutionary Psychology, arguing that Bayesian Fundamentalism doesn’t care about what is going on in the mind, only about the constraints of the environment and what the rational solution to the problem is given those constraints. They argue that despite this position, Bayesian models really &lt;em&gt;do&lt;/em&gt; make mechanistic assumptions about representations and processes. For example, in critiquing &lt;a href=&quot;/quals/theory%20learning/2016/01/09/Kemp2007.html&quot;&gt;Kemp et al.&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;However, it is not Bayes’ Rule or even the notion of overhypotheses that drives the prediction; rather it is the particular overhypotheses that were built into the model. In other words, the model was endowed with the capability to recognize a particular pattern (viz., regularity across words in which perceptual dimensions are relevant to meaning), so the fact that it indeed recognizes that pattern when presented with it is not surprising or theoretically informative. (pg. 178)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;They also argue that despite emphasizing how important it is to specify the specific environmental constraints giving rise to the model, Bayesian Fundamentalists rarely do so. And, even if they did, it is nearly impossible to know what the right set of constraints are; in general it is possible to give a post-hoc argument for a particular set of constraints being “rational”:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The relevant environment for rational action could be the local environment present in the laboratory task, similar situations (however defined) that the person has experienced, all experiences over the person’s life, all experiences of our species, all experiences of all ancestral organisms traced back to single cell organisms, and so on. Furthermore, once the relevant environment is specified and characterized, the rational theorist has considerable flexibility in characterizing which relevant measures or statistics from the environment should enter into the optimality calculations. (pg. 181)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Jones &amp;amp; Love note furthermore that from an evolutionary perspective, it is not &lt;em&gt;behavior&lt;/em&gt; that is optimized but &lt;em&gt;mechanism&lt;/em&gt; that is optimized. Whatever the existing mechanism is, it is perhaps a slightly more optimized version of the mechanism that was there before, and so on. That means only that if the behavior is optimized at all, it is locally optimal, not globally optimal, because it depends on the process of optimization that has occurred. But even then, many things may simply be accidents or side effects and are not even optimized at all.&lt;/p&gt;

&lt;p&gt;Jones &amp;amp; Love argue that Bayesian Fundamentalism says nothing about development because Bayesian models are mechanism-free, and therefore it is not clear what develops:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;One key question for any developmental model is what develops. In rational models, the answer is that nothing develops. Rational models are mechanism-free, leaving only information sampled to change over time. Although some aspects of development are driven by acquisition of more observations, other aspects of development clearly reflect maturational changes in the mechanism. (pg. 182)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, the suggest that Bayesian Enlightenment holds promise by:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Treating Bayesian representations (e.g. the generative model or parameteters of conjugate priors) as actual hypotheses about psychological representations&lt;/li&gt;
  &lt;li&gt;Investigating Bayesian approximation algorithms (e.g. MCMC) as possible algorithmic-level processes&lt;/li&gt;
  &lt;li&gt;Performing rational analysis not within the context of the environment, but within the context of a mechanistic model&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;Jones &amp;amp; Love actually make a lot of good points about how Bayesian models can be useful and fruitful. I disagree with their claims that they aren’t (or weren’t) already being used in that way. I also disagree with their characterization that Bayesian models aren’t informative if they recognize the patterns they were built to recognize (e.g. in the discussion of Kemp et al.). It is the connection with the data that makes them informative: if we have a hypothesis about how people reason in a particular domain, we can instantiate that explicit hypothesis in a Bayesian model and verify that the hypothesis does actually produce the same behavior as people. The model is just a tool for making the assumptions and implications of the hypothesis explicit.&lt;/p&gt;

&lt;p&gt;I am not sure why Jones &amp;amp; Love think that Bayesian models aren’t committed to hypotheses about psychological representation. The sense in which the computation of Bayesian models “doesn’t matter” is that Bayesians are not committed to the specific way by which the predictions of the model are computed; what they are committed to is the structure of the model. The structured representations offered by Bayesian models are their most powerful feature, in my opinion.&lt;/p&gt;
</description>
        <pubDate>Tue, 12 Jan 2016 02:59:51 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/challenges%20for%20probabilistic%20models%20of%20cognition/2016/01/12/Jones2011.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/challenges%20for%20probabilistic%20models%20of%20cognition/2016/01/12/Jones2011.html</guid>
        
        
        <category>Challenges for probabilistic models of cognition</category>
        
      </item>
    
  </channel>
</rss>
