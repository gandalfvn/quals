<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Quals Reading Notes</title>
    <description>Notes on readings for my qualifying exams.
</description>
    <link>http://jhamrick.github.io/quals/</link>
    <atom:link href="http://jhamrick.github.io/quals/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Fri, 08 Jan 2016 12:23:30 -0800</pubDate>
    <lastBuildDate>Fri, 08 Jan 2016 12:23:30 -0800</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>In defense of the simulation theory</title>
        <description>&lt;p&gt;&lt;span id=&quot;Goldman1992&quot;&gt;Goldman, A. I. (1992). In Defense of the Simulation Theory. &lt;i&gt;Mind And Language&lt;/i&gt;, &lt;i&gt;7&lt;/i&gt;(1-2), 104–119. doi:10.1111/j.1468-0017.1992.tb00200.x&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Goldman replies to &lt;a href=&quot;/quals/theory%20of%20mind/2016/01/07/Stich1992.html&quot;&gt;Stich &amp;amp; Nichols&lt;/a&gt;, conceding some of the points they make but also providing further evidence for simulation theory.&lt;/p&gt;

&lt;p&gt;Goldman begins by first pointing out that the simulation theory isn’t a substantial departure from previous approaches in cognitive science, as it falls under the umbrella of &lt;em&gt;knowledge-poor&lt;/em&gt; approaches (e.g. heuristics and biases) in contrast to &lt;em&gt;knowledge-rich&lt;/em&gt; approaches (e.g. rules and symbols). Thus, the simulation theory isn’t a “radical departure” from other paradigms in cognition.&lt;/p&gt;

&lt;p&gt;In the next section, Goldman points out that theory theory, as described by Stich &amp;amp; Nichols, depards substantially from other formulations of the theory theory. For example, he states that “in the philosophical literature it has been widely assumed that it should be easy to formulate the principles of folk psychology because they are &lt;em&gt;platitudes&lt;/em&gt;, i.e. truths that are obvious to everyone” (pg. 106). Additionally, Goldman discusses “the assumption that folk psychological platitudes are culturally produced and culturally transmitted” (pg. 106-7). Both of these claims seem dubious, and presumably Stich &amp;amp; Nichols woult not adhere to either of them. Thus, their definition of theory theory isn’t the same as everyone else’s. So, while criticisms of claims like those don’t necessarily “knock-down” the theory theory, “these arguments do cast doubt on some popular variations of the theory-theory theme, and highlight the difficulties that must be met by any detailed development of the theory-theory” (pg. 108).&lt;/p&gt;

&lt;p&gt;Next, Goldman discusses the relationship to simulations in other domains (i.e., mental imagery). Here he makes the distinction between &lt;em&gt;process-driven&lt;/em&gt; and &lt;em&gt;theory-driven simulation&lt;/em&gt;, and concedes that mental simulation may indeed be theory-driven; thus, it is necessary to show that the simulation theory is process driven, not just that it is a simulation. This leads into a discussion on introspection, which cannot on its own be used to discriminate between process- and theory-driven simulations. Goldman argues that, for the present purposes, the point of introspection isn’t to distinguish between the two, just to show that theory of mind may indeed involve some form of simulation (as a first step).&lt;/p&gt;

&lt;p&gt;Goldman next responds to Stich &amp;amp; Nichols point about simplicity, which was that the theory theory gets the control mechanism “for free” while simulation theory gets the database “for free”. He makes a good point that it isn’t entirely clear what “for free” means, and argues that simulation theory does indeed get the control “for free” by arguing that the process that interprets the output of the decision-making process needs to be present for any theory, and thus it would indeed be available to off-line simulation as well. (I think Goldman misses the point of what “control” means here, but I’ll get back to this in the takeaways section).&lt;/p&gt;

&lt;p&gt;Next, Goldman discusses additional evidence from autism for simulation theory. Specifically, that there is evidence that autistic children are perfectly capable at theorizing about mechanistic or behavioral processes (just not mentalistic ones), and that they do have a concept of desire, but that they have difficulty evaulating what is a “reasonable” desire based on the situation. He concludes that these pieces of evidence are easily explained by simulation theory, but not theory theory.&lt;/p&gt;

&lt;p&gt;He also discusses the developmental literature discussed by Stich &amp;amp; Nichols, and argues that the results they cite are contradicted by other studies and may be due to confusing task demands. He also suggests the possibility that younger children may understand beliefs, but do not classify those beliefs as being the same as &lt;em&gt;knowledge&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Finally, Goldman replies to Stich &amp;amp; Nichols’ arguments about cognitive penetrability, and in particular, the claim that simulations should predict the same impenetrable behaviors that people exhibit when they make predictions about others. Goldman argues that this only should be the case if the inputs to the simulation are &lt;em&gt;identical&lt;/em&gt; to when people are in the situation themselves, and only if the interpretation of those simulations is identical as well. He questions whether this would actually be the case in the examples cited by Stich &amp;amp; Nichols.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;I like Goldman’s further characterization of simulation as being either &lt;em&gt;theory-driven&lt;/em&gt; or &lt;em&gt;process-driven&lt;/em&gt;. That is, the simulation is either driven from a theory (and therefore is something like a simulation of a mental model), or it is actually an execution of a real process in the brain. In the latter case I wonder if it is even really appropriate to call it “simulation”, as it’s not a &lt;em&gt;simulation&lt;/em&gt; of the process by which you would act, it &lt;em&gt;is&lt;/em&gt; the process by which you would act. A &lt;em&gt;simulation&lt;/em&gt; actually implies that it is a copy of a process that necessarily makes certain assumptions and simplifications. I guess it is a simulation in the sense that the real process is being used in the &lt;em&gt;context&lt;/em&gt; of a simulation (i.e., pretend inputs).&lt;/p&gt;

&lt;p&gt;In discussing the role of the controller, I think Goldman misses the point of why this is important. I made this point in my notes on &lt;a href=&quot;/quals/theory%20of%20mind/2016/01/07/Gordon1992.html&quot;&gt;Gordon&lt;/a&gt; as well: knowing what “pretend” inputs to feed the simulation is a nontrivial task. It cannot simply be a matter of trial-and-error. There has to be some additional mechanism guiding the decisions to change certain dimensions of the input rather than others, and what they get changed &lt;em&gt;to&lt;/em&gt;. This is related to the difficult problem of determining what information is relevant and what information is irrelevant; knowing the answer to these questions requires some sort of higher-level abstract knowledge (like a theory!).&lt;/p&gt;

&lt;p&gt;I do think Gordon brings up some good points regarding empathy. For example, people often feel physiological pain when they see someone else in pain (e.g. if you watch a video of someone cutting their finger with a knife while cutting vegetables, it &lt;em&gt;feels&lt;/em&gt; painful to see). Thus, it is not implausible that there is some amount of processing that goes on that engages the same systems that we use when where are in the situation ourselves. However, I don’t think this can be the only explanation. There are also cases where we understand someone else’s behavior while feeling relatively apathetic about it. If I simply read “John cut his finger”, I don’t feel physical pain, but if I see a video of the same thing happening, I do (though, of course, even that is still not as painful as actually experiencing it). But, I still understand how John is feeling in either case. Based on the arguments of Gordon and Goldman, I don’t see how just reading “John cut his finger” would be something that could be fed into the simulator without actually constructing the full scenario (i.e. putting it into a format that the simulation can handle), in which case it ought to predict that you would feel pain.&lt;/p&gt;

&lt;p&gt;This whole debate seems so black-and-white, though. Why does it have to be &lt;em&gt;only&lt;/em&gt; theory-theory, or &lt;em&gt;only&lt;/em&gt; simulation theory? Is it really so impossible for there to be some combination of using higher-order structured knowledge (i.e., a theory) in combination with reuse of existing perceptual, motor, or emotional systems (i.e., simulation)?&lt;/p&gt;
</description>
        <pubDate>Fri, 08 Jan 2016 03:29:43 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/08/Goldman1992.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/08/Goldman1992.html</guid>
        
        
        <category>Theory of mind</category>
        
      </item>
    
      <item>
        <title>Folk psychology: simulation or tacit theory?</title>
        <description>&lt;p&gt;&lt;span id=&quot;Stich1992&quot;&gt;Stich, S. P., &amp;amp; Nichols, S. (1992). Folk Psychology: Simulation or Tacit Theory? &lt;i&gt;Mind And Language&lt;/i&gt;, &lt;i&gt;7&lt;/i&gt;(1-2), 35–71. doi:10.1111/j.1468-0017.1992.tb00196.x&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Stich &amp;amp; Nichols argue against simulation theory in favor of theory theory. They first give an overview of their interpretation of what simulation theory is positing, which seems consistent with what I’ve read so far. They make a particular point about calling the simulation theory &lt;em&gt;off-line simulation&lt;/em&gt; of the decision-making system. That is, they argue that simulation theory says that to run a simulation, the decision-making system is taken off-line. It is fed pretend beliefs and desires, and it outputs a decision, which is then fed to another system which explains and interprets decisions in terms of their inputs. They also clarify what they mean by “theory”, which is (as they put it) in the “wide” sense: that a theory need not necessarily be symbolic/logical, but could take the form of other representations like a neural network as well.&lt;/p&gt;

&lt;p&gt;Stich &amp;amp; Nichols go through a number of arguments for the simulation theory, and give counter evidence to each one.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;What are the rules of the folk psychological theory?&lt;/em&gt; This is interpreting a “theory” in the narrow sense. And besides, not being able to specify the rules doesn’t make the theory invalid (example: language, folk physics).&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Mental simulation models have been successful.&lt;/em&gt; “Simulation” used in the context of “mental simulation” is actually closer to a theory that is ust not rule/sentence like.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Children can’t possibly have as sophisticated a theory as theory theory suggests.&lt;/em&gt; Theory theory doesn’t necessarily posit a theory that is the same type of stuff that you learn in the classroom. Besides, children learn other very complicated things (language, folk physics)&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Simulation theory is simpler than theory theory.&lt;/em&gt; Specifying the “control mechanism” for coming up with pretend beliefs and desires is non-trivial. Essentially, in theory-theory, you get the control for free, while in simulation theory, you get the “database” of knowledge for free. They are equally complex theories.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Sometimes we imagine how others behave by imagining ourselves in their situation.&lt;/em&gt; Imagery is not the same thing as simulation. For example, to imagine yourself walking through your house and counting the number of windows, it’s not just running an off-line simulation—the knowledge about the number of windows has to come from somewhere.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Simulation theory is supported by developmental evidence.&lt;/em&gt; It is consistent with the evidence; that doesn’t it predicts it. Theory theory is also consistent with the evidence.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Autistic children are poor at engaging in pretend play and at reasoning about theory of mind.&lt;/em&gt; As in the previous point, simulation might be able to account for this, but so can theory theory.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After refuting the arguments of off-line simulation theory, Stich &amp;amp; Nichols present a few arguments in favor of theory theory:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;There is developmental data that simulation theory can’t explain.&lt;/em&gt; In particular, there is evidence that children have accurate knowledge about what other children have seen and yet still make incorrect judgments about their beliefs. That is, it seems like children have all the correct inputs that would be used to run an off-line simulation, yet they still come up with the wrong answer, but only for &lt;em&gt;other&lt;/em&gt; people—they give a different answer themselves.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Theory theory is cognitively penetrable.&lt;/em&gt; Simulation theory is not cognitive penetrable. In particular, because it’s a simulation of one’s own behavior, if there are any quirks in our own behavior that we don’t consciously know about, they should still show up in our predictions of other people’s behavior. However, if the theory posited by theory theory doesn’t include these things explicitly, then it will make the wrong predictions because it is cognitively penetrable. There are many examples of cases where people predict that they (or others) would behave in a certain way, but then actually behave differently themselves. Thus the can’t have just been running a simulation.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;I agree with pretty much all the points made by Stich &amp;amp; Nichols, though I do think they are a bit vague on the notion of what a theory is. Ideally, even if you can’t specify a set of rules, you should still be able to roughly sketch the mechanism by which it works, or by which it is acquired.&lt;/p&gt;

&lt;p&gt;I do like how Stich &amp;amp; Nichols explicitly contrast offline simulation with other forms of simulation. They state that they don’t think offline simulation is involved at all, which I would probably agree with—though I do think some form of “simulation” probably is used. Perhaps the better term to use here is “emulation” (ala &lt;a href=&quot;/quals/mental%20imagery/2016/01/01/Grush2004.html&quot;&gt;Grush&lt;/a&gt;), to imply that it is a simulation from a &lt;em&gt;model&lt;/em&gt;, not a simulation from &lt;em&gt;oneself&lt;/em&gt;. Such a model could easily be a component in a theory; thus, this notion isn’t at odds with theory theory.&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Jan 2016 11:25:00 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/07/Stich1992.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/07/Stich1992.html</guid>
        
        
        <category>Theory of mind</category>
        
      </item>
    
      <item>
        <title>The simulation theory: objections and misconceptions</title>
        <description>&lt;p&gt;&lt;span id=&quot;Gordon1992&quot;&gt;Gordon, R. M. (1992). The Simulation theory: Objections and misconceptions. &lt;i&gt;Mind And Language&lt;/i&gt;, &lt;i&gt;7&lt;/i&gt;(1-2), 11–34. doi:10.1111/j.1468-0017.1992.tb00195.x&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Gordon attempts to define his own definition of &lt;em&gt;simulation theory&lt;/em&gt; (ST), and contrasts it with &lt;em&gt;theory theory&lt;/em&gt; (TT) as well as other forms of ST (“putting oneself in their shoes”, the Model Model).&lt;/p&gt;

&lt;p&gt;First, Gordon explains why ST is not “putting oneself in the other’s place”. He says that ST is not this, because people don’t actually put themselves in others’ places most of the time (usually they are &lt;em&gt;told&lt;/em&gt; to do that). Rather, being told to put oneself in the other’s place means that “you shouldn’t just project your own situation and psychology on the other”. This implies that, to begin with, you &lt;em&gt;are&lt;/em&gt; projecting your own situation and psychology on the other, which is the core of what ST is about.&lt;/p&gt;

&lt;p&gt;Gordon goes on to explain what he means by &lt;em&gt;projection&lt;/em&gt;, and specifically, &lt;em&gt;total projection&lt;/em&gt;. Total projection is the idea of projecting your own situation and psychology onto someone else, without making any adjustment (spatial or otherwise). This type of total projection is the default mode of simulation. In using projection, we search for explanations that would have caused ourselves to behave in the same way as other people. We can also adjust these projections in order to better explain other people’s actions, for example by imagining ourselves in their spatial location:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In general terms, what you are doing is shifting the locations and vectors of environmental features on your egocentric map—that is, the mental map in which things and events are represented in relation to yourself, here, and now—so as properly to engage your location-specific or vector-specific tendencies to action or emotion.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Alternately, you can “prep” yourself to have the appropriate attitudes or beliefs that would be necessary to understand the behavior of others. For example, to understand why someone likes the music of a particular artist that you do not particularly like, you find a suitable alternative that you enjoy to a similar degree and then use that alternative as a stand in for understanding the other person’s intentions (e.g. to go see that person in concert). Importantly, because we can make these adjustments to the projection, this allows us to simulate counterfactuals, which allows us to generate appropriate explanations.&lt;/p&gt;

&lt;p&gt;Gordon contrasts ST with the idea that we might just use generalizations or laws to explain other people’s behavior. He argues that this cannot be the case, as generalizations/laws on their own are too brittle; we need to know when they are relevant so that we can appropriately apply them. Knowing when to apply them requires using our own knowledge about how the world works; this therefore ends up being just another way of using projection.&lt;/p&gt;

&lt;p&gt;He also contrasts ST with the “Model” Model, which is the idea that simulation is just a model that you can use to run simulations (similar to running a simulation on a model of an airplane). Gordon argues that with the “Model” Model, you &lt;em&gt;would&lt;/em&gt; need something like a theory to explain the outputs of the model, as it is essentially a black box. But, under the hypothesis of projection, this is not necessary because you yourself already understand the workings of the model because you &lt;em&gt;are&lt;/em&gt; the model.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;From a computational standpoint, it is really difficult to see how Gordon’s version of the ST would work. It seems that the core of his argument is that because we are projecting ourselves, we get for free the ability to generate explanations of behavior. I don’t think this follows, and in particular, it still doesn’t give us any insight into how those explanations are generated (it feels a bit like saying, “we generate explanations of other people’s behavior by using ourselves to generate explanations of other people’s behavior”). I also think he doesn’t give enough credit to the difficulty in knowing what things about the projection to change. He basically implies it is as simple as “trying out various options until one clicks”, but for a given scenario there might be many possible things you could try to change. How do you know which dimension requires modification? And then how do you know the right modification to make? And then what does it mean for an explanation to “click”? What is a “good enough” explanation? All of these things seem like they need some form of metacognition or higher-level, structured knowledge—for example, a theory.&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Jan 2016 09:42:08 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/07/Gordon1992.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/07/Gordon1992.html</guid>
        
        
        <category>Theory of mind</category>
        
      </item>
    
      <item>
        <title>Representational momentum and related displacements in spatial memory: a review of the findings</title>
        <description>&lt;p&gt;&lt;span id=&quot;Hubbard2005&quot;&gt;Hubbard, T. L. (2005). Representational momentum and related displacements in spatial memory: A review of the findings. &lt;i&gt;Psychonomic Bulletin And Review&lt;/i&gt;, &lt;i&gt;12&lt;/i&gt;(5), 822–851. doi:10.3758/BF03196775&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;Hubbard consolidates a huge body of literature regarding the phenomena of &lt;em&gt;displacement&lt;/em&gt;. While this has sometimes been referred to as &lt;em&gt;representational momentum&lt;/em&gt;, Hubbard prefers the term “displacement” because the effect can be found in many domains:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Forward displacement (in the direction of motion)&lt;/li&gt;
  &lt;li&gt;Downward displacement (due to gravity)&lt;/li&gt;
  &lt;li&gt;Reduced displacement after contact (due to friction)&lt;/li&gt;
  &lt;li&gt;Inward displacement along a curved trajectory (due to centripetal force)&lt;/li&gt;
  &lt;li&gt;Displacement in auditory pitch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are many variables that seem to influence the amount and direction of displacement:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Target velocity (increased velocity increases displacement)&lt;/li&gt;
  &lt;li&gt;Direction of motion (horizontal displacement is typically greater than vertical displacement, and vertical displacement is affected by gravity)&lt;/li&gt;
  &lt;li&gt;Target identity and shape (displacement tends to be consistent with the typical direction certain shapes move)&lt;/li&gt;
  &lt;li&gt;Target weight (larger downward displacement for larger objects)&lt;/li&gt;
  &lt;li&gt;Target animacy&lt;/li&gt;
  &lt;li&gt;Surrounding context (e.g. if there are “landmarks”, if the stimuli are realistic scenes, if the motion is from the point of view of an observer, etc.)&lt;/li&gt;
  &lt;li&gt;Physical constraints (e.g. walls that the object can bounce off of)&lt;/li&gt;
  &lt;li&gt;Structure of the motion (e.g. oscillitory motion)&lt;/li&gt;
  &lt;li&gt;Internal vs. externally caused motion, as in the launching task&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is also influenced by factors applying to the participant themselves:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Attention&lt;/li&gt;
  &lt;li&gt;Fixation point (eye movements)&lt;/li&gt;
  &lt;li&gt;Action plans&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Methodologically, displacement has been found for smooth-moving targets, for sequential series of discrete stimuli, for static images that imply motion, and for targets whose motion is controlled by the participant. The effect of displacement seems to decay after a period of time, though the results on this are somewhat mixed. Response measures have included judging same/different, clicking on the remembered position of the target, or reaching for the target.&lt;/p&gt;

&lt;p&gt;Hubbard suggests that displacement does not solely reflect objective physical laws, though it might strongly be influenced by them. Importantly, this is because displacement can be affected by other factors (such as landmarks, or whether the motion is internally or externally caused) besides just kinematics and dynamics. Regarding naive physics, he suggests that “displacement might reflect subjective consequences of physical principles, rather than objective physical principles per se” (pg. 842).&lt;/p&gt;

&lt;p&gt;In terms of a computational-level theory of displacement, Hubbard suggests that displacement serves the purpose of bridging the gap between perception and action by helping to localize the future spatial locations of objects. This is consistent with the idea of forward models, though displacement seems to often be less than what one would expect from an accurate prediction into the future. Hubbard suggests this might be a tradeoff for prediciting motion that is either predictable or unpredictable: some displacement helps bias action towards predictable motion, but it is also less than what would be expected, which makes it easier to recover when the motion is unpredictable.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;I would be really curious to see if you could get the effects of displacement from a computational-level model whose goal is to execute an action to “catch” a moving object. This would involve predicting the next state of an object based on a variety of factors (position, rotation, velocity, shape, etc.) but also executing the action (with a latency similar to that found in humans). Would you end up finding the same types of displacement effects? Would this model predict new things about displacement?&lt;/p&gt;

&lt;p&gt;Additionally, I wonder to what extent displacement/prediction is used simply as a tracking device. That is, it’s not used to inform the motor system of where to execute its action—just to help the perceptual system track the object through time.&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Jan 2016 07:41:52 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/representational%20momentum/2016/01/07/Hubbard2005.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/representational%20momentum/2016/01/07/Hubbard2005.html</guid>
        
        
        <category>Representational momentum</category>
        
      </item>
    
      <item>
        <title>Representational momentum</title>
        <description>&lt;p&gt;&lt;span id=&quot;Freyd1984&quot;&gt;Freyd, J. J., &amp;amp; Finke, R. A. (1984). Representational Momentum. &lt;i&gt;Journal Of Experimental Psychology: Learning, Memory, and Cognition&lt;/i&gt;, &lt;i&gt;10&lt;/i&gt;(1), 126–132. doi:10.1037/0278-7393.10.1.126&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Freyd &amp;amp; Finke present a number of experiments showing an effect of &lt;em&gt;representational momentum&lt;/em&gt; in which people’s memories for the position/rotation of an object are distorted in the direction of implied motion of the object.&lt;/p&gt;

&lt;h1 id=&quot;methods&quot;&gt;Methods&lt;/h1&gt;

&lt;p&gt;In Experiment 1, they showed participants a sequence of four images and asked them to determine whether the third and fourth images were the same or different. The first three images showed a rectangle in different orientations resulting from rotating it in a particular direction. The fourth image was either the same as the third, or rotated slightly forward or backwards from the third image (though not as much as the angular separation between the first three images). Freyd &amp;amp; Finke found that people were significantly faster and more accurate at judging the same (15.8% error) and reverse (6.4% error) stimuli, compared to the forward (43.9% error) stimuli.&lt;/p&gt;

&lt;p&gt;In Experiment 2, they controlled for the effect of the result being somehow due to “some configural property of the inducing displays, independent of their temporal order”. Thus, they swapped the first and second images in the presentation. This caused the representational momentum effect to disappear entirely.&lt;/p&gt;

&lt;p&gt;In Experiment 3, Freyd &amp;amp; Finke asked whether the representation momentum effect was due to sensory or cognitive processing. To test this, they increased the ISI (inter-stimulus interval) times to 500ms and 750ms (from 250ms). With these larger times, they still found the representational momentum effects, though they were less strong than at 250ms.&lt;/p&gt;

&lt;p&gt;They additionally ran another control study to see if it was just whether people were extrapolating forward to the next image in the sequence (after the first three images). Instead of having small perturbations to the rotation of the third image, they used the next image in the sequence. They did not find the representational momentum effect using these larger rotations.&lt;/p&gt;

&lt;h1 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h1&gt;

&lt;p&gt;n/a&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;There seems to be something about people’s predictive processing of visual stimuli that causes them to misremember the location or pose of objects. I wonder if something like this could be explained by a system that, rather than storing the actual current perception, stores an expectation for the next perception. If there has recently been motion, then this would give rise to something like the representational momentum effect. It doesn’t quite fit with their experimental setup, though, which is that they showed each image for 250ms, then removed it for 250ms, then showed the next, etc. These long presentation times mean that apparent motion isn’t generated, so it doesn’t seem as if people are estimating the angular velocity and then propagating that forward—if they were, then presumably the last control experiment that Freyd &amp;amp; Finke found would have still found the effect. Perhaps one explanation for this is that the visual system is estimating velocity from the implied motion, but it only propagates it for a fraction of the time forward—i.e., it doesn’t estimate the ISI time and factor that in. If this were the case, then it should be possible to demonstrate that different angular velocities result in memory distortions that are either closer or further away from the true image.&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Jan 2016 05:54:51 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/representational%20momentum/2016/01/07/Freyd1984.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/representational%20momentum/2016/01/07/Freyd1984.html</guid>
        
        
        <category>Representational momentum</category>
        
      </item>
    
      <item>
        <title>Visual perception and interception of falling objects: a review of evidence for an internal model of gravity</title>
        <description>&lt;p&gt;&lt;span id=&quot;Zago2005&quot;&gt;Zago, M., &amp;amp; Lacquaniti, F. (2005). Visual perception and interception of falling objects: a review of evidence for an internal model of gravity. &lt;i&gt;Journal Of Neural Engineering&lt;/i&gt;, &lt;i&gt;2&lt;/i&gt;(3), S198–208. doi:10.1088/1741-2560/2/3/S04&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this article, Zago &amp;amp; Lacquaniti review evidence for the hypothesis that the brain has an internal model of gravity. They begin by layout out the computational problem, which is to solve for &lt;em&gt;time-to-contact&lt;/em&gt; (TTC). Specifically, if an object starts at height $h_0$, and follows the equation $h(t)=h_0-0.5gt^2$, then solving for TTC involves solving for $h(t)=0$.&lt;/p&gt;

&lt;p&gt;Next, Zago &amp;amp; Lacquaniti discuss evidence from visual perception that people take gravity into account. They summarize some work from Kim &amp;amp; Spelke (1992) suggesting that infants are sensitive to the downward acceleration of gravity. Adults are also sensitive to gravity in visual perception, with evidence that it affects the perception of causality and naturalness of motion, absolute distance and size of falling objects, and even biological motion (details aren’t given for these examples, though, just citations).&lt;/p&gt;

&lt;p&gt;Zago &amp;amp; Lacquaniti also give evidence that people take gravity into account when trying to catch a falling ball. For example, if a ball is dropped directly over a person’s hand, muscle activity can be detected just before the ball reaches the hand (with a delay accounting for processing of the motor system), and that the time this activity is detected is consistent even if the ball is dropped from different heights. The expected mass of the ball affected the magnitude of the muscle activity, but not the timing. Similar effects were shown even when people didn’t have visual access to the ball, though in these cases it was a reflex behavior, rather than anticipatory behavior. Still, the results indicate that “subjects are able to reach an internal estimate of the expected duration of fall even in the absence of vision, as demonstrated by the fact that they can easily detect randomly interspersed cases of inaccurate timing of the auditory cue” (pg. S200).&lt;/p&gt;

&lt;p&gt;However, Zago &amp;amp; Lacquaniti also discuss the fact that visual perception is remarkably bad at estimating or detecting changes in acceleration. They suggest that, rather than people maintaining an estimate of gravity that can change, gravity is an “ecological constraint” that cannot change. They present evidence that shows that astronauts (in 0g) still predict objects to fall in the same manner as they do on earth. Even after spending extended time in 0g, astronauts only adapted very slightly, and even then readjusted to 1g almost immediately upon returning to Earth. Similarly, experiments conduced on participants using computer simulated gravity revealed that people were consistently able to punch a ball moving under 1g but prematurely punched a ball moving under 0g. Interestingly, they also found that participants seemed to ignore acceleration when the task was less motor based, i.e., if they just had to click a button to intercept the ball, leading to higher performance in 0g than in 1g. Thus, it would appear that perceptual and motor task demands determine whether the mind’s internal estimate of gravity is recruited, or whether just visual cues are used.&lt;/p&gt;

&lt;p&gt;Based on computational results (see Algorithm), it seems that people have an internal model of gravity that is fixed at 1g. Some adaptation can occur by modifying other parameters in the model, but not the actual estimate of the gravitational acceleration. There are results that suggest that the model of gravity is calculated by the vestibular system, and that this system is recruited less for tasks involving unnatural motion.&lt;/p&gt;

&lt;h1 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h1&gt;

&lt;p&gt;Zago &amp;amp; Lacquaniti discuss possible computation models of how people’s estimate of gravity works. One hypothesis is that they have two separate models of gravity (one for 0g and one for 1g). Another hypothesis is that they have a single model of gravity, but change it’s parameters. This second hypothesis can additionally be broken down into two hypotheses about &lt;em&gt;which&lt;/em&gt; particular parameter is tuned. The model predicts:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{TTC}(t)=\frac{-\hat{v}(t)+\sqrt{\hat{v}(t)^2+2\hat{g}\hat{h}(t)}}{\hat{g}}&lt;/script&gt;

&lt;p&gt;where $\hat{v}$ and $\hat{h}$ are the visually estimated velocity and height, respectively, and where $\hat{g}$ is the estimate of gravitational acceleration. If $\lambda$ is then the amount of time it takes to execute the action, then the action should be triggered at time $\epsilon$, where $\mathrm{TTC}(\epsilon)=\lambda$. If this model is used assuming $\hat{g}=1g$, but the true gravitational acceleration is $0g$, then the resulting error will be:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta=\frac{\hat{g}\lambda^2}{2v_0}&lt;/script&gt;

&lt;p&gt;This error could be reduced by either changing the value of $\hat{g}$ or the value of $\lambda$. If $\hat{g}$ is reduced, then this should affect responses under both 0g and 1g (because it is a variable in the TTC equation), but if $\lambda$ is reduced, then this should affect only 0g.&lt;/p&gt;

&lt;p&gt;On the other hand, if an entirely separate $0g$ model is learned, then it should predict:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{TTC}(t)=\frac{\hat{h}(t)}{\hat{v}(t)}&lt;/script&gt;

&lt;p&gt;Empirical results suggest that adaptation is consistent with the first TTC model that has a fixed value of $\hat{g}=1g$ but which modifies $\lambda$.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;It is not too surprising that gravity plays such a prominent role in our ability to reason about the world. As it is essentially an invariant in our environments, it is also not surprising that it seems to be largely invariant to adaptation as well. What’s interesting are the results that seem to show that sometimes the vestibular estimate of gravity is used, while other times it isn’t. Perhaps, when faced with unnatural motion tasks (e.g. -1g), our brains are consistently computing the error in predicting motion for objects. If there is consistent error, then perhaps it switches to not relying on the internal estimate of gravity, and relies solely on visual cues. If the motion is consistent with natural gravitational acceleration, then that estimate is used—though it’s also interesting that sometimes that estimate is used for visual perception while other times it only seems to be recruitable when people are engaged in motor action. I’m not entirely sure what the right explanation is for all of these results. When do we take gravity into account, and when do we not, and why?&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Jan 2016 04:18:24 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/physical%20reasoning/2016/01/07/Zago2005.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/physical%20reasoning/2016/01/07/Zago2005.html</guid>
        
        
        <category>Physical reasoning</category>
        
      </item>
    
      <item>
        <title>Physical imagery: kinematic versus dynamic models</title>
        <description>&lt;p&gt;(missing reference)&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Schwartz asks: is physical imagery based on kinematics or dynamics? Specifically, does it only rely on spatial information (kinematic model, KM), or does it also incorporate information about things like forces (dynamic model, DM)? Schwartz shows through a series of four experiments that physical imagery is consistent with the dynamics account.&lt;/p&gt;

&lt;h1 id=&quot;methods&quot;&gt;Methods&lt;/h1&gt;

&lt;p&gt;In Experiment 1, participants completed two tasks in one of two orders. One task was the “judge” task, which was to view two differently size glasses of water (with the same level of water) and to determine which glass needed to tilt farther for the water to spill out. The other task was the “tilt” task, in which participants physically rotated empty glasses with their eyes closed and imagined the water in the glasses. The hypothesis was that if people were using KM, if people performed the “judge” task before the “tilt” task, then their judgments should affect the outcome of the tilt (as the tilt would just be based on a spatial outcome). If people were using DM, then doing the “judge” task before the “tilt” task should interfere with people’s mental imagery (which based on previous work is accurate for tilting but inaccurate for judging). They found the results that were consistent with DM: when tilting first, people (correctly) tilted the thin glass further, but when judging first, they either tilted the wide glass further or tilted the two glasses the same. People were almost entirely incorrect in the explicit judgments, and judgments did not correspond to tilts.&lt;/p&gt;

&lt;p&gt;In Experiment 2, participant performed the “tilt” task but were told to either imagine that the liquid in the glass was water or molasses. The hypothesis was that if people are using KM, then the type of liquid should have no effect; if they are using DM, then they should tilt the molasses glasses further, because the molasses moves more slowly than water. The results were again consistent with the DM account. People tilted the thin glasses further than wide glasses (as expected) and also turned the molasses glasses further than the water glasses. Schwartz makes an important point in the discussion of this experiment:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;People rely on the temporal coordinations of physical imagery to allow inferences to emerge; they do not first decide what the inference should be and then adjust the timing of things to portray that inference. (pg. 449)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In Experiment 3, Schwartz had people tilt glasses normally, or tilt them starting from a horizontal position. He also had people perform the tasks lying down. In addition to the tilting task, Schwartz had people rate the quality of their mental imagery, in order to gauge how well people were able to imagine the water in the glass. The idea was to see whether gravity would have an effect on people’s ability to perform the task. He found that, as before, people were able to perform the task when both they and the glass were upright. Interestingly, people could also perform the task if they were lying down, provided the glass was still upright with respect to gravity. They could not perform the task if the glass was horizontal, saying things like “the water began to pour out when I started to tilt the glass” (pg. 452). In terms of the quality of their imagery when the glass was sideways, it was typically high initially (before they started tilting), but image quality degraded as they began the glass tilt. These results also support the DM account.&lt;/p&gt;

&lt;p&gt;Experiment 4 looked at another manipulation to test how perceptual information affects imagery. In this experiment, Schwartz had regular glasses and weighted glasses, and hypothesized that people would turn the weighted cups less than the regular cups because the extra weight from the glass introduces a torque that increases as the amount of rotation increases. In particular, as the water level decreases, people should increasingly under rotate because they have to rotate further into the torque. As predicted, this is what Schwartz found. He also ran a control version in which he had people rotate the glasses to a specified rotation (without water, 45 degrees). People were able to perform this task nearly perfectly, suggesting that the results from the main experiment were not due to people’s inability to represent the angle of the glass. Rather, Schwartz suggests that the effect is due to a relationship between the rate of work exerted in turning the glass and rate of change of the water. As the class is turned, the rate of work increases, causing the water to change more quickly, and thus causing people to underrotate.&lt;/p&gt;

&lt;h1 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h1&gt;

&lt;p&gt;n/a&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;These experiments indicate that dynamic information is clearly incorporated in our ability to visualize objects and our actions on those objects. Schwartz makes the argument that, contrary to other mental imagery accounts, we do not represent transformations by computing the target spatial orientation, but that we represent the control and apply that control until the orientation is achieved. I like this account, but I still don’t quite know how it fits into the mental &lt;em&gt;rotation&lt;/em&gt; account. It cannot be that people just randomly pick a direction of rotation, as then their response times would average out to be constant.&lt;/p&gt;

&lt;p&gt;Perhaps, as argued by &lt;a href=&quot;/quals/mental%20imagery/2015/12/31/Just1976.html&quot;&gt;Just and Carpenter&lt;/a&gt;, people do rely on some sort of feature matching in order to determine the direction of rotation—but not the final orientation. Then, they apply the relevant control in order to move the shape in that direction until they match the correct orientation. It’s still not clear to me exactly how you would tell if you’ve reached the correct orientation… I suppose if people only rotate one part of the shape, then that local piece would be easy to compare. Then, once the local rotation is found, people presumably know what the angle is and can rotate the rest of the shape to that angle, and don’t necessarily need to provide the control.&lt;/p&gt;

&lt;p&gt;The control account is very compelling, but I wonder if there are really some cases where we use purely visual imagery, and other cases where we use dynamic imagery. For example, in the mental rotation case I just described, could one component of that be using dynamic imagery, while another component just uses spatial imagery? Would it be possible to test for this? Do these two cases differ in important ways (i.e., does it really matter if we only use one or the other)? I would expect that it does. I have read a lot of stuff in robotics that is based on knowing the goal state and applying control to get there, but I have read less about simply applying control until some conditions are satisfied (i.e. it is not explicitly a goal state in terms of pose). I need to think more about how these two things are different (or if they are different at all). Perhaps the latter isn’t really actually that different—it’s just that some higher level planner is making the goal states be not very far away from the current state.&lt;/p&gt;
</description>
        <pubDate>Wed, 06 Jan 2016 14:33:50 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/physical%20reasoning/2016/01/06/Schwartz1999.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/physical%20reasoning/2016/01/06/Schwartz1999.html</guid>
        
        
        <category>Physical reasoning</category>
        
      </item>
    
      <item>
        <title>Representing statics as forces in equilibrium</title>
        <description>&lt;p&gt;&lt;span id=&quot;Freyd1988&quot;&gt;Freyd, J. J., Pantzer, T. M., &amp;amp; Cheng, J. L. (1988). Representing Statics as Forces in Equilibrium. &lt;i&gt;Journal Of Experimental Psychology: General&lt;/i&gt;, &lt;i&gt;117&lt;/i&gt;, 395–407. doi:dx.doi.org/10.1037/0096-3445.117.4.395&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Freyd et al. hypothesize that the mind represents dynamic forces, even for static scenes. In particular, they point out that in static scenes, it is not truly the case that there are no forces: it is just that forces are in equilibrium. They run a series of four experiments to test this hypothesis, finding that people’s memory for static objects is distorted in the direction that those objects would move if they were unsupported.&lt;/p&gt;

&lt;h1 id=&quot;methods&quot;&gt;Methods&lt;/h1&gt;

&lt;p&gt;In Experiment 1, Freyd et al. showed participants a scene with a plant either on a table or hanging from a hook for 250ms. The scene was removed for 250ms at which point an identical scene was showed for 250ms, except that the table or hook was removed. The scene was again removed for 250ms, and then a new scene was shown which was either (1) the same, (2) different, with the plant moved slightly upwards, or (3) different, with the plant moved slightly downwards. Participants had to determine whether the last scene was the same as the original one or not. They found that people were quite accurate at determining “same” trials (8-13% error) and worse at detecting “down” trials (57% error) than “up” trials (37% error).&lt;/p&gt;

&lt;p&gt;Experiment 2 was a control in which Freyd et al. never showed any form of support. The results showed basically no difference between the “down” trials (33%) vs. the “up” trials (34%). Interestingly, though, the error rate for the “same” trials was higher than in Experiment 1 (26%).&lt;/p&gt;

&lt;p&gt;Experiment 3 was similar to Experiments 1 and 2, except that they used a different display (a lock hanging from a hook) and tested different distances from the true position. This was done in order to get a more fine-grained estimate of the distortion in people’s memories. As in Experiments 1 and 2, they found distortions when there was support, and that the shift was positive (i.e. “down” trials had more error) when there was support and that it was close to zero when there was no support.&lt;/p&gt;

&lt;p&gt;In Experiment 4, Freyd et al. tested another new display, this time with a block resting on a spring. This allowed them to test for distortions in memory both in the upward and downward directions. There were two conditions: one in which there was initially no block (which would predict a downward shift, as the spring should compress), and one in which there was initially a block (which would predict an upward shift, as the spring should decompress). The results supported the predicted direction of memory distortions.&lt;/p&gt;

&lt;h1 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h1&gt;

&lt;p&gt;n/a&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;These are a cool set of results, related to representational momentum, that indicate that people have strong perceptual expectations about the way that objects should move. In particular, I think the results of Experiment 4 are really striking: it’s not just that people expect things to move down due to gravity, but that they expect them to move in the way they actually would. I expect you would find similar results with objects that typically move up (e.g. balloons). I also wonder if you would find these effects if they depended on higher-level knowledge about object properties (such as mass). For example, in the spring experiment, if you knew the block was extremely light (and thus would not compress the spring), would the memory distortion still take place?&lt;/p&gt;
</description>
        <pubDate>Wed, 06 Jan 2016 07:09:25 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/physical%20reasoning/2016/01/06/Freyd1988.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/physical%20reasoning/2016/01/06/Freyd1988.html</guid>
        
        
        <category>Physical reasoning</category>
        
      </item>
    
      <item>
        <title>The experience of force: the role of haptic experience of forces in visual perception of object motion and interactions, mental simulation, and motion-related judgments</title>
        <description>&lt;p&gt;&lt;span id=&quot;White2012a&quot;&gt;White, P. A. (2012). The experience of force: The role of haptic experience of forces in visual perception of object motion and interactions, mental simulation, and motion-related judgments. &lt;i&gt;Psychological Bulletin&lt;/i&gt;, &lt;i&gt;138&lt;/i&gt;(4), 589–615. doi:10.1037/a0025587&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, White proposes a theory of action and perception that is based on the notion of force. Specifically, he argues that during our interactions with the world, we perceive force from our haptic system (along with other sensory modalities), and these perceptions get stored in memory along with the relevant actions associated with them. Then, when we perceive new situations, we activate these stored representations which allows us to make predictions and judgments about motion and other factors.&lt;/p&gt;

&lt;p&gt;First, White discusses evidence for forward models of action in the motor system, as well as evidence for the role of mechanoreceptor feedback. What is sounds like he proposes is a sort of forward model like this:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;[\mathbf{x}_{t+1}, \mathbf{s}_{t+1}] = f(\mathbf{x}_t,\mathbf{s}_t,\mathbf{u}_t)&lt;/script&gt;

&lt;p&gt;where $\mathbf{x}$ is the state of the system, $\mathbf{s}$ is the sensory information (e.g. from the haptic system), and $\mathbf{u}$ are the controls (forces) of the system. A prediction error for the sensory information (e.g. mechanoreceptor feedback) is also computed:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{\delta}_t=\mathbf{s}_t - \hat{\mathbf{s}}_t&lt;/script&gt;

&lt;p&gt;where $\mathbf{s}_t$ is the predicted sensory information and $\hat{\mathbf{s}}_t$ is the true sensory information. The feedback $\mathbf{\delta}_t$ is thus the error signal, which is going to be zero when our predictions of force are accurate. White also argues that perception of additional object properties (texture, rigidity, mass, etc.) are computed based on sensory information from mechanoreceptors. I’ll denote these properties as $\mathbf{\pi}$.&lt;/p&gt;

&lt;p&gt;All of these different sources of information are stored in long-term memory, roughly (it seems) in the form of tuples such as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{m}_t=[\mathbf{x}_t,\mathbf{\delta}_t,\mathbf{\pi}]&lt;/script&gt;

&lt;p&gt;White describes these as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A stored representation of an action on an object is a multimodal episodic trace combining haptic information such as the disposition and movement of the limbs during execution of the action, visual information about body movement and the associated motion of the object acted on, auditory information such as sounds elicited by contact between extremity and object, and in principle, information in any sensory modality. Internally available information such as the content of the forward model also forms part of the representation. (pg. 607)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Importantly, we store our &lt;em&gt;prediction error&lt;/em&gt; of sensory information, rather than the absolute sensory information itself.
These stored representations are activated by matching to similar perceptual stimuli (e.g. visual stimuli).&lt;/p&gt;

&lt;p&gt;White uses this formulation of stored representations to offer a unifying account for several lines of research:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The storing of sensory feedback, rather than direct sensory information, predicts that when making judgments about force in terms of one moving object acting on a stationary, we assign notions of force &lt;em&gt;from&lt;/em&gt; the moving object (because we do store $\mathbf{u}_t$) but not &lt;em&gt;to&lt;/em&gt; the moving object (because, for static objects, the sensory prediction error should be zero). If both objects are moving, however, we should assign a notion of force that the second object is applying to the first object because the sensory prediction error is nonzero. This explains, for example, Michottean launching effects.&lt;/li&gt;
  &lt;li&gt;To the extent that visual perception of motion matches stored representations corresponding to actions, we should perceive that motion as being internally caused. This extends to biological plausibility as well. Importantly, biologically generated motion has different velocity profiles than, for example, two nonbiological objects colliding—thus visual motion that matches the biological motion velocity profile should be interpreted as more biological.&lt;/li&gt;
  &lt;li&gt;Representational momentum&lt;/li&gt;
  &lt;li&gt;Perception of inanimate entities as intentional&lt;/li&gt;
  &lt;li&gt;Mental simulation&lt;/li&gt;
  &lt;li&gt;Perception of mass&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;This is a surprisingly consistent and satisfying account of how perception arises from the combination of visual and haptic feedback. Assuming people do store information as something like $\mathbf{m}_t$ defined above, and they have access to forward an inverse models, it should be possible to reconstruct $\mathbf{u}_t$ (from both $\mathbf{x}_t$ and $\mathbf{x}_{t+1}$), which is consistent with White’s assertions. I am skeptical, though, that all we are doing is “storing” and “matching” representations. It is not at all clear to me how it would work to match the motion of a 2D ball (e.g. in the Michotte experiments) to the stored motion of ourselves. Additionally, it sounds like White is advocating for something like an exemplar model, but I find it much more likely that we use our experiences to build structured forward or inverse models. There may be multiple forward models (as suggested by Kawato) that are perhaps combined in certain ways, but give that there is evidence for some generalization (also described by Kawato), I would be very surprised if all that was going on was just storing and matching exemplars.&lt;/p&gt;
</description>
        <pubDate>Wed, 06 Jan 2016 04:47:29 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/motor%20control%20and%20action/2016/01/06/White2012a.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/motor%20control%20and%20action/2016/01/06/White2012a.html</guid>
        
        
        <category>Motor control and action</category>
        
      </item>
    
      <item>
        <title>Prediction precedes control in motor learning</title>
        <description>&lt;p&gt;&lt;span id=&quot;Flanagan2003&quot;&gt;Flanagan, R. R., Vetter, P., Johansson, R. S., &amp;amp; Wolpert, D. M. (2003). Prediction precedes control in motor learning. &lt;i&gt;Current Biology&lt;/i&gt;, &lt;i&gt;13&lt;/i&gt;(2), 146–150. doi:10.1016/S0960-9822(03)00007-1&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Flanagan et al. describe an experiment in which participants must grip an object with their index finger and thumb, and move it in a straight line to a target. The dynamics of the object were modified so that when they moved it in the horizontal plane, a proportional vertical force was applied to the object. Thus, to learn to move it in a straight line, participants had to adapt to the vertical force.&lt;/p&gt;

&lt;p&gt;Flanagan et al. found that participants took a long time (about 70 trials) before they were able to fully adjust their trajectories to be straight. However, they took much less time (about 10 trials) to adjust the force with which they gripped the object to match that of the corresponding load force. These results suggest that there are two internal models (one for the grip force, and one for the arm trajectory) that are being learned at separate rates. Specifically, Flanagan et al. suggest that in the first case, it is a forward kinematic model that is being learned, while in the second case, it is a inverse dynamics model that is being learned. This is consistent with the demands of the task: the novel dynamics of the object require learning a new mapping from desired trajectory to motor commands (the inverse model), but they do not require learning a new mapping for controlling the load force. Rather, the motor system needs only to predict the load force so that it can appropriately adjust for it.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;This paper basically answers the question I ended with in &lt;a href=&quot;/quals/motor%20control%20and%20action/2016/01/05/Kawato1999.html&quot;&gt;Kawato’s review&lt;/a&gt;: learning operates independently in the forward and inverse models. Flanagan et al. suggest that, computationally, this may be able to be explained by something like &lt;a href=&quot;/quals/physical%20reasoning%20with%20dynamics%20models/2015/12/20/Nguyen-Tuong2011.html&quot;&gt;distal teacher learning&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Tue, 05 Jan 2016 13:30:48 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/motor%20control%20and%20action/2016/01/05/Flanagan2003.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/motor%20control%20and%20action/2016/01/05/Flanagan2003.html</guid>
        
        
        <category>Motor control and action</category>
        
      </item>
    
  </channel>
</rss>
