<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Quals Reading Notes</title>
    <description>Notes on readings for my qualifying exams.
</description>
    <link>http://jhamrick.github.io/quals/</link>
    <atom:link href="http://jhamrick.github.io/quals/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sat, 09 Jan 2016 16:24:23 -0800</pubDate>
    <lastBuildDate>Sat, 09 Jan 2016 16:24:23 -0800</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>The role of imagistic simulation in scientific thought experiments</title>
        <description>&lt;p&gt;&lt;span id=&quot;Clement2009&quot;&gt;Clement, J. J. (2009). The Role of Imagistic Simulation in Scientific Thought Experiments. &lt;i&gt;Topics In Cognitive Science&lt;/i&gt;, &lt;i&gt;1&lt;/i&gt;(4), 686–710. doi:10.1111/j.1756-8765.2009.01031.x&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Clement poses the &lt;em&gt;fundamental paradox of thought experiments&lt;/em&gt; as being “How can findings that carry conviction result from a new experiment conducted entirely within the head?” (pg. 687). He attempts to provide a resolution to this paradox based on the idea of “imagistic simulation” (a.k.a. mental simulation, mental imagery, etc.) with evidence provided through a case study of a single expert subject (S2). S2 is posed with the following “spring problem”:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A weight is hung on a spring (Fig. 1). The original spring is replaced with a spring made of the same kind of wire, with the same number of coils, but with coils that are twice as wide in diameter. Will the spring stretch from its natural length more, less, or the same amount under the same weight? (Assume the mass of the spring is negligible). Why do you think so? (pg. 689)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Clement specifies his definition of “thought experiment” (TE) as being “the act of considering an untested, concrete system (the ‘experiment’ or case) and attempting to predict aspects of its behavior” (pg. 690-1). He isolates a number of TEs produced by S2, and analyzes the use of imagistic simulation in those TEs. He finds that S2 spontaneously engaged in “personal action projection (spontaneously redescribing a system action in terms of a human action) consistent with the use of kinesthetic imagery, depictive getures (gestures that depict objects, forces, locations, or movements of entities), and imagery reports” (pg. 694). Some of these are characteristic of using static imagery, but others are characteristic of &lt;em&gt;dynamic&lt;/em&gt; imagery.&lt;/p&gt;

&lt;p&gt;To explain the use of dynamic imagery, Clement appeals to the idea of &lt;a href=&quot;https://en.wikipedia.org/wiki/Motor_program#Schmidt.E2.80.99s_schema_theory&quot;&gt;motor schema theory&lt;/a&gt; in which imagistic simulations are driven by the use of motor programs/schema. Specifically, he identifies four possible components to an imagistic simulation which allow such simulations to apply to situations which have not previously been encountered:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Applying a schema to a use outside its normal domain&lt;/li&gt;
  &lt;li&gt;Converting implicit knowledge into explicit knowledge&lt;/li&gt;
  &lt;li&gt;Including spatial reasoning&lt;/li&gt;
  &lt;li&gt;Combining multiple schemas into a &lt;em&gt;compound simulation&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Additionally, Clement argues that imagistic simulations are used to generate “enhanced” imagery:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;…the main source of conviction in the simulations is the tapping of implicit knowledge embedded in motor schemas and its conversion into explicit knowledge. The extreme case makes differences in implicit expectations larger and more ‘perceivable’ in this case. (pg. 698)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Clement argues that this formulation of imagistic simulation resolves the TE paradox:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;To address the TE paradox, the idea of perceptual motor schemas running imagistic simulations, and the four more specific sources of conviction within imagistic simulations… can account for ways that a TE can &lt;em&gt;feel&lt;/em&gt; empirical (via the inspection of imagery) or necessary (via confident schema extension or spatial reasoning). Yet these processes actually involve a considerable amount of nonformal reasoning and inference that goes beyond prior observations. (pg. 704)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In discussing the case study with S2, Clement also touches on the distinction between evaluative (disconfirmatory/confirmatory) and generative thought experiments.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;I like this characterization of what thought experiments (and perhaps, even, mental simulations more generally) are; I think Clement is right in tying the use of thought experiments to action &lt;em&gt;and&lt;/em&gt; perception.&lt;/p&gt;
</description>
        <pubDate>Sat, 09 Jan 2016 07:35:52 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/thought%20experiments/2016/01/09/Clement2009.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/thought%20experiments/2016/01/09/Clement2009.html</guid>
        
        
        <category>Thought experiments</category>
        
      </item>
    
      <item>
        <title>&quot;What if...&quot;: The use of conceptual simulations in scientific reasoning</title>
        <description>&lt;p&gt;&lt;span id=&quot;Trickett2007&quot;&gt;Trickett, S. B., &amp;amp; Trafton, J. G. (2007). “What if…”: The Use of Conceptual Simulations in Scientific Reasoning. &lt;i&gt;Cognitive Science&lt;/i&gt;, &lt;i&gt;31&lt;/i&gt;(5), 843–875. doi:10.1080/03640210701530771&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Trickett &amp;amp; Trafton experimentally explore the use of &lt;em&gt;conceptual simulations&lt;/em&gt; by expert scientists when reasoning about problems in their domain of expertise. They have two main hypotheses: that conceptual simulations are a core strategy used in scientific reasoning, and that they are used in particular to reason about situations in which there are high levels of uncertainty (e.g. partial knowledge, violation of expectation, etc.). They define conceptual simulation as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;…a three-step process that consists of first, visualizing some situation; second, carrying out one or more operations on it; and third, seeing what happens. The third part of the process—seeing what happens—is crucial. It distinguishes “what if” thinking from purely imagining because during this third phase &lt;em&gt;causal reasoning&lt;/em&gt; occurs to the results of the manipulation(s) of the second phase.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In their experiments, Trickett &amp;amp; Trafton found that scientists do spontaneously use conceptual simulation and that they use it in cases where their expectations are violated (i.e. they have more uncertainty):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The research shows how conceptual simulation helps resolve uncertainty: conceptual simulation facilitates reasoning about hypotheses by generating an altered representation under the purported conditions expressed in the hypothesis and providing a source of comparison with the actual data, in the process of alignment by similarity detection. (pg. 866)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Additionally, the results of these experiments combined with other results from the literature suggest that conceptual simulations are used in situations where there the answer truly is unknown. In other cases, people can rely on background knowledge, existing models, etc.:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Frequently, studies of experts employ problems that are well-understood for an expert and that can be solved by recalling either this very problem (i.e., by model-based search) or another that shares the same deep structure (i.e., by analogy; cf. Chi et al., 1981). In contrast, our studies show experts reasoning about problems for which neither they nor anyone else knows the answer. (pg. 867)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That is, conceptual simulation is a type of model &lt;em&gt;construction&lt;/em&gt; (pg. 866).&lt;/p&gt;

&lt;h1 id=&quot;methods&quot;&gt;Methods&lt;/h1&gt;

&lt;p&gt;In Experiment 1, Trickett &amp;amp; Trafton performed an &lt;em&gt;in vivo&lt;/em&gt; study of scientists across several different domains of science. The scientists were filmed while they analyzed their own data, either individually (with a verbal protocol) or collaboratively. The utterances of the scientists were coded for instances of conceptual simulation, for hypotheses, for and for other scientific reasoning strategies (data focus, empirical test, consult a colleague, tie-in with theory and domain knowledge, analogy, or alignment). They found that data focus was the most commonly used strategy. The next most frequently used strategies were tie-in with theory, alignment, and conceptual simulation; these were used at approximately the same frequency.&lt;/p&gt;

&lt;p&gt;In analyzing the relationship between strategies, they found that conceptual simulations were almost always followed by a process of alignment, which was then usually either the end of the chain of reasoning, or which was followed by a return to data focus. Trickett &amp;amp; Trafton hypothesized that this sequence of conceptual simulation followed by alignment was used “to link the internal (result of the conceptual simulation) and external (phenomena in the data) representations” (pg. 858).&lt;/p&gt;

&lt;p&gt;They additionally coded the data for hypotheses that were generated either based on evidence that violated expectations or which was consistent with expectations. They found that conceptual simulation more frequently followed violation of expectation hypotheses than those that did not have a violation of expectation, suggesting that the scientists used conceptual simulation in situations where they were more uncertain.&lt;/p&gt;

&lt;p&gt;To causally test the previous hypothesis (that conceptual simulations are used in situations with higher uncertainty), Trickett &amp;amp; Trafton ran a second experiment. In Experiment 2, they recruited expert cognitive psychologists and gave them different scenarios and results of phenomena they were familiar with. The results were either consistent with the given scenario (Expectation Confirmation, EC) or inconsistent (Expectation Violation, EV). The scientists were instructed to engage in a process of explaining the data, and again were recorded doing so. Consistent with the results of Experiment 1, they found that conceptual simulations were used more frequently in the EV condition than in the EC condition, at a rate of approximately 2:1.&lt;/p&gt;

&lt;h1 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h1&gt;

&lt;p&gt;n/a&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;These types of “conceptual simulations”, as well as thought experiments like those described by &lt;a href=&quot;/quals/thought%20experiments/2016/01/08/Gendler1998.html&quot;&gt;Gendler&lt;/a&gt;, are really fascinating in that they seem to be qualitatively a very different sort of simulation than, for example, motor simulation or even certain types of mental imagery (like that which is used in language understanding). I think a relevant question is: are such types of conceptual simulations drawing on the same types of simulation processes that serve lower levels of reasoning? I would expect the answer to be “sometimes”, but I don’t have a good intuition for why certain low-level simulations would be available for high-level conceptual reasoning (e.g. imagery) while others wouldn’t (e.g. accurate simulation of physics via the motor system).&lt;/p&gt;
</description>
        <pubDate>Sat, 09 Jan 2016 04:33:40 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/thought%20experiments/2016/01/09/Trickett2007.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/thought%20experiments/2016/01/09/Trickett2007.html</guid>
        
        
        <category>Thought experiments</category>
        
      </item>
    
      <item>
        <title>Galileo and the indispensability of scientific thought experiment</title>
        <description>&lt;p&gt;&lt;span id=&quot;Gendler1998&quot;&gt;Gendler, T. S. (1998). Galileo and the Indispensability of Scientific Thought Experiment. &lt;i&gt;The British Journal For the Philosophy of Science&lt;/i&gt;, &lt;i&gt;49&lt;/i&gt;(3), 397–424.&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Gendler argues that thought experiments are important and justified for the use of scientific inquiry, using Galileo’s thought experiment demonstrating that two objects with different masses fall at the same rate. The thought experiment goes, imagine that two objects with different weights are strapped together. Because the lighter object falls slower than the heavier object, it must slow the heavier object down, and thus the speed that they fall together must be somewhere in between the speed of the heavy object alone and the light object alone. But, together, they also have a greater mass, meaning that together they should fall faster than the heavy object alone. Thus, for there to not be a contradiction, the objects must actually fall at the same speed.&lt;/p&gt;

&lt;p&gt;Gendler addresses the claim that thought experiments are just another form of deductive/inductive reasoning from a set of explicit premises, and explains what they add over and above pure argumentation. Specifically, she argues against the &lt;em&gt;Elimination Thesis&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;The Elimination Thesis&lt;/strong&gt;: Any conclusion reached by a (successful) scientific thought experiment will also be demonstrable by a non-thought-experimental argument. (pg. 398)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;She breaks the Elimination Thesis down into two separate claims:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;The Dispensibility Thesis&lt;/strong&gt;: Any good scientific thought experiment can be replaced, without loss of demonstrative force, by a non-thought-experimental argument. (pg. 401)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;The Derivativity Thesis&lt;/strong&gt;: The justificatory force of any good scientific thought experiment can only be explained by the fact that it can be replaced, without loss of demonstrative force, by a non-thought-experimental argument. (pg. 401)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;First, Gendler rephrases the thought experiment in terms of a few propositions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(1) Natural speed is mediative [averaging].&lt;/li&gt;
  &lt;li&gt;(2) Weight is additive.&lt;/li&gt;
  &lt;li&gt;(3) Natural speed is not directly proportional to weight.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next, she goes about disproving the Dispensibility Thesis by giving an example set of alternate premises that an Aristotelian might adhere to, given their existing belief that objects fall at the same weight:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(4) Natural speed is not physically determinate for strapped-bodies.&lt;/li&gt;
  &lt;li&gt;(5) Weight is not physically determinate for strapped-bodies.&lt;/li&gt;
  &lt;li&gt;(6) Natural speed and weight are mediative for strapped-bodies that are &lt;em&gt;united&lt;/em&gt; (two objects). Natural speed and weight are additive for strapped-bodies that are &lt;em&gt;unified&lt;/em&gt; (one object).&lt;/li&gt;
  &lt;li&gt;(7) Natural speed and weight for strapped-bodies are determined by a &lt;em&gt;degree of connectedness&lt;/em&gt; ($C$) such that the speed/weight of $B_1$-strapped-to-$B_2$ where $B_1$ has $w_1$ and $B_2$ has $w_2$ will be: $C(w_1+w_2)+(1-C)(w_1+w_2)/2$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That is, the Aristotelian takes this “degree of connectedness” as being a key relevant property, and thus is able to preserve the idea that speed and weight are proportional. Of course, this claim seems a bit ridiculous, and that is because, as Gendler claims, the thought experiment is revealing to us tacit assumptions that we did not realize we had:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(8) Natural speed and weight are physically determined.&lt;/li&gt;
  &lt;li&gt;(9) Entification [number of objects/entities that something counts as] is not physically determined.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, it is important to note that “prior to the thought experiment, the Aristotelian is explicitly committed to the &lt;em&gt;negation&lt;/em&gt; of (3), and this background commitment serves as a filter through which apparently contrary evidence will inevitably be reinterpreted” (pg. 409). Thus, it does not necessarily follow that anyone given (1) and (2) would reach the conclusion of (3)—particularly if they already thought (3) was false, they would look for ways of explaining away or disproving (1) and (2) so that (3) would remain false.&lt;/p&gt;

&lt;p&gt;Next, Gendler moves on to disproving the Derivativity Thesis by showing that through the thought experiment knowledge has been gained, both in the sense that something new has been learned, and that this new knowledge is justified.&lt;/p&gt;

&lt;p&gt;The first part of this argument (that something new has been learned) is a straightforward claim: presumably, altering one’s beliefs so that they &lt;em&gt;negate&lt;/em&gt; a piece of knowledge counts as having learned something “new”, as it is not simply a combination of previous beliefs. But even more importantly, the Aristotelian is led to think of speed as a different type of concept entirely: rather than being a derivative of weight, it is something else. As Gendler puts it, “it brings the Aristotelian to recognize the inadequacy of his conceptual framework for dealing with phenomena which—through the contemplation of this imaginary case—he comes to recognize as always having been part of his world.” (pg. 412)&lt;/p&gt;

&lt;p&gt;The second part of the argument (that the knowledge is justified) is trickier. Gendler asks, “Why should we think that our pre-theoretical beliefs about the structure of the physical world are reliable?” (pg. 414). She doesn’t really give an answer to this question, but does argue that we do have (implied veridical) knowledge of the world, but it is not accessible by argument alone: it requires something like a thought experiment to tap into it.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;This is a somewhat different take on the notion of simulation than what I’ve been thinking about so far. Although Gendler doesn’t refer to thought experiments as simulations per se, they are related in the sense of being a mental reproduction of something in the world.&lt;/p&gt;

&lt;p&gt;I have more thoughts about this, but I’m too tired tonight to get them in a coherent enough form to write down. I will include them on my notes for the other papers in this topic (thought experiments) tomorrow.&lt;/p&gt;
</description>
        <pubDate>Fri, 08 Jan 2016 12:31:41 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/thought%20experiments/2016/01/08/Gendler1998.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/thought%20experiments/2016/01/08/Gendler1998.html</guid>
        
        
        <category>Thought experiments</category>
        
      </item>
    
      <item>
        <title>Against simulation: the argument from error</title>
        <description>&lt;p&gt;&lt;span id=&quot;Saxe2005&quot;&gt;Saxe, R. (2005). Against simulation: the argument from error. &lt;i&gt;Trends In Cognitive Sciences&lt;/i&gt;, &lt;i&gt;9&lt;/i&gt;(4), 174–179. doi:10.1016/j.tics.2005.01.012&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;Saxe, like &lt;a href=&quot;/quals/theory%20of%20mind/2016/01/08/Gopnik1992.html&quot;&gt;Gopnik &amp;amp; Wellman&lt;/a&gt;, argues in favor of folk psychological theories rather than simulation theory.&lt;/p&gt;

&lt;p&gt;Saxe specifically cautions against the use of the &lt;em&gt;mirror system&lt;/em&gt; as evidence for the simulation theory of mind. The mirror system consists of neurons which are active both when performing an action and watching someone else perform an action. However, the mirror system (e.g., right inferior parietal cortex, inferior frontal gyrus) is &lt;em&gt;not&lt;/em&gt; the same system as the one that is recruited when reasoning about true or false beliefs (bilateral temporo-parietal junction, right anterior superior temporal sulcus, medial prefrontal cortex, posterior cingulate).&lt;/p&gt;

&lt;p&gt;Saxe also recaps some of the behavioral and developmental evidence against the simulation theory, and gives some more recent examples as well. For example,  an adult and a child are sitting at a table with a circular dish of red and green beads, and a square dish of yellow beads. Both the child and the adult see that a bead from the square dish was put in the bag, but only the child knows the color of the bead (green). When the child is asked what color the adult thinks the bead is, children overwhelmingly say “red”. That is, they seem to think something along the lines of, “ignorance means you get it wrong”. Saxe gives an eloquent explanation of how this is inconsistent with the strong notion of simulation theory:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The ‘incorrect inputs’ defence does not work, though, for the systematic errors described above, such as young children’s conflation of ignorance and ‘being wrong’. Remember that children who know that the selected bead is green reported that the ignorant adult observer, ‘A’, thinks the bead is red. If the child were simulating A, she might accurately express A’s ignorance, or else she might assimilate A to the self and judge that A thinks the bead is green. Simulation Theory offers no account of children’s actual systematic error. It is not enough to say that they used incorrect inputs: the theory must explain why the inputs were wrong in just this way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, Saxe suggest a compromise between theory theory and simulation theory. In this formulation, there is both a theory and a simulator, but that theory determines (or at least influences) what inputs are used in the simulator.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;I find the idea that there is really something somewhere in between theory theory and simulation theory more plausible than either on their own, though I would expect the simulation theory not so much to be using the same decision making process that we use when make our own decisions, but a learned generative model of it. One way to think about it might be like this: at any given moment, there are many competing desires and urges governing our behavior (I need to study for quals because they are in less than two weeks, but I want to play video games, and yet I’m also a bit hungry, and also the apartment needs to be cleaned, and ooh, that looks shiny). These all combine in some way and one behavior is ultimately produced (I am studying for quals). In the moment, perhaps, I might be able to explain &lt;em&gt;my own&lt;/em&gt; behavior as being the input that has the highest weight (though I am doubtful this level of introspection exists). But what about explaining my past behavior? I no longer have access to all the inputs, as those presumably reside only in short term memory. Thus, I need to have some function that allows me to reason about &lt;em&gt;my own&lt;/em&gt; behavior with missing information. One possibility for this is to have a full generative (joint) model over actions, desires, beliefs, and perceptions. Then, with such a joint model, any subset of these variables can be conditioned on to produce predictions or inferences. Such a model can also be used to reason about other people, though in that case something additional is needed to choose the appropriate values of things to condition on. Furthermore, the structure of a generative model such as this needs to be learned, which is also where the notion of a theory comes in—a meta form of reasoning that guides the process of constructing, and then using, the model.&lt;/p&gt;

</description>
        <pubDate>Fri, 08 Jan 2016 09:45:02 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/08/Saxe2005.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/08/Saxe2005.html</guid>
        
        
        <category>Theory of mind</category>
        
      </item>
    
      <item>
        <title>Why the child&#39;s theory of mind really is a theory</title>
        <description>&lt;p&gt;&lt;span id=&quot;Gopnik1992&quot;&gt;Gopnik, A., &amp;amp; Wellman, H. M. (1992). Why the Child’s Theory of Mind Really Is a Theory. &lt;i&gt;Mind And Language&lt;/i&gt;, &lt;i&gt;7&lt;/i&gt;(1-2), 145–171. doi:10.1111/j.1468-0017.1992.tb00202.x&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Gopnik &amp;amp; Wellman lay out a wealth of developmental evidence supporting the theory theory, and describe precisely what they take the theory theory to be and what it would predict. They begin with a definition of “theoretical construct”:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theoretical constructs are abstract entities postulated, or recruited from elsewhere, to provide a separate causal-explanatory level of analysis that accounts for evidential phenomena… Theoretical constructs need not be definitely unobservable, but they must be appeals to a set of entities removed from, and underlying, the evidential phenomena themselves… Theoretical constructs do not work independently, they work together in systems characterized by laws or structure. (pg. 146-7)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There are two primary characteristics of theories: they are abstract, and they coherent. Because of these two properties, theories are able to generate predictions about a wide range of behavior, including situations that go beyond the data experienced so far. Theories may also produce incorrect predictions, in cases where they do not perfectly match the phenomena being described. Theories additionally provide &lt;em&gt;explanatory depth&lt;/em&gt; because, by definition, they “produce interpretations of evidence, not simply descriptions of evidence and generalizations about it”. Finally, theories can be modified in the face of new, conflicting evidence.&lt;/p&gt;

&lt;p&gt;Gopnik &amp;amp; Wellman describe theory change as follows. First, there is an initial theory. If evidence is encountered that conflicts with this theory, it will initially be ignored as noise, and eventually start to accumulate as ad-hoc auxiliary rules tacked on to the original theory. Eventually, as the original theory gets unweildy, if a new competing theory is encountered or developed, it may replace the old theory. Elements of the new theory may first appear in the auxiliary rules, but its full predictive power is not utilized until it fully subsumes the old theory.&lt;/p&gt;

&lt;p&gt;Gopnik &amp;amp; Wellman argue that this process of theory change is evident in the development of theory of mind in children, particularly between 2.5 and around 4 years of age. There are several stages of development:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;2-year-olds have some understanding of desires and perceptions. However, these concepts are relatively rudimentary and are “nonrepresentational”: desires are “drives towards object” and perceptions are an “awareness of objects”. This leads to simple causal rules like “if X can see an object, and X desires the object, then X will try to get the object”.&lt;/li&gt;
  &lt;li&gt;At 3, children begin to exhibit some (non-representational) understanding of beliefs, though it does not seem to have much of an effect on their behavior. While it seems that they typically have a notion of belief that directly reflects what is true in the world, there is some evidence that 3-year-olds can acknowledge the idea of a false belief. Even if they might be able to acknowledge the idea of a false belief, though, their theory of how the world works does not include beliefs as a factor in producing actions.&lt;/li&gt;
  &lt;li&gt;By 4 or 5 years, children seem to have developed a “representational theory of mind” in which desires, perceptions, beliefs, and pretenses are all included as &lt;em&gt;representations&lt;/em&gt; of reality, rather than being reflections of reality itself (i.e., &lt;em&gt;intentional&lt;/em&gt;).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Gopnik &amp;amp; Wellman next cite considerable evidence supporting this theory:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Explanations&lt;/strong&gt;: 2-year-old’s answers to questions like “why is she doing that?” tend to reflect desires (“she wants it”), while 3- and 4-year-old’s answers reflect beliefs (“she thinks it’s there”).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Predictions&lt;/strong&gt;: With the initial desire-perception theory, children should be able to predict that desires will differ and that people will do things given that they have a desire. They should also be able to predict the perceptions of other, but not that things might be perceived &lt;em&gt;differently&lt;/em&gt; by multiple people. And, they should not be able to predict anything that relies on the notion that people have different beliefs that may not reflect the true world. Evidence for this comes from the false-belief task, but other types of tasks as well (appearance-reality tasks, questions about sources of beliefs, understanding pictorial representation systems).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interpretations&lt;/strong&gt;: Also with the initial desire-perception theory, children should initially ignore evidence that is counter to the theory. Indeed, children will misreport evidence they have just heard (e.g. someone saying “I think it is blue”, when it is white).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transitional phenomena&lt;/strong&gt;: Children seem to initially realize that concepts like perception and desire do not necessarily reflect the world (i.e., they &lt;em&gt;misrepresent&lt;/em&gt; what is true) earlier than they come to the same realization about beliefs. When pressed, 3-year-olds may beging to explain inconsistencies in terms of misrepresentation when those inconsistencies are pointed out to them.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next, Gopnik &amp;amp; Wellman turn to their critique of simulation theory. They focus on two main issues: first, “the centrality of your own mind in any understanding of the minds of others”, and second, “how development should proceed” (pg. 160). The first point is similar to the one made by &lt;a href=&quot;/quals/theory%20of%20mind/2016/01/07/Stich1992.html&quot;&gt;Stich &amp;amp; Nichols&lt;/a&gt; about how a simulation should give the same results for oneself and for others (provided the inputs are correct). For the second point, they argue that ST should predict a developmental trajectory in which children make errors on states that are “hard” to simulate, and that they should originally make “egocentric” errors that reflect an inability to modify their simulations to reflect other people’s states. They give empirical evidence based on these two issues:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;“Three-year-old children make false attributions to themselves, that exactly parallel their false attributions to others.”&lt;/em&gt; From a simulation point of view, it doesn’t make sense why children would make mistakes about their &lt;em&gt;own&lt;/em&gt; mental states if they were just reading off the results from whatever mechanism is used to run the simulations. Additionally, 3-year-olds are good at reporting their mental states in terms of desires and perceptions, but not beliefs. Why would the simulation account predict &lt;em&gt;a priori&lt;/em&gt; for this to be the case? What is special about beliefs in the simulation case that makes them harder to simulate?&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;“Three-year-old children make correct non-egocentric attributions to themselves and others for some mental states.”&lt;/em&gt; Children can report that other people have different perceptions and desires than their own, so in terms of the simulation account, they are clearly able to adjust their simulations to incorporate other people’s perceptions and desires. Why can they not do the same for beliefs?&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;“Children refer to only some mental states in their explanations, and refer to different mental states at different stages of their development.”&lt;/em&gt; Younger children tend to give explanations about other people’s behavior in terms of desires, while older children appeal to beliefs. And, in either of these scenarios, children are preferring beliefs in desires over “fears and fantasies, pains and sensations or any of a vast number of experientially available mental states”. What about simulation theory would predict that they answer in this way? Why is “she fears that kitty is lost” a dispreferred explanation to “she wants the kitty” or “she thinks the kitty is there”? In theory theory, desires and beliefs are core constructs, and thus make sense as the types of concepts that children appeal to.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;“Children’s understanding of other psychological phenomena changes in parallel with their understanding of false belief.”&lt;/em&gt; While three-year-olds can report their beliefs, they seem unable to report &lt;em&gt;how&lt;/em&gt; they got that information, even if it was just told to them. Additionally, three-year-olds seem to be unable to gauge the reliability of a source of information (e.g. distinguishing between someone who knows, vs. someone who is just guessing). Theory theory predicts these other types of behavior because knowing where information comes from and how reliable it is is related to the idea of seeing beliefs as representational—i.e., separate entities from what they correspond to in the world. It is not clear why simulation theory would &lt;em&gt;a priori&lt;/em&gt; predict these types of results.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;In reading this paper I had a bit of a small epiphany regarding why simulation seems to be such a loaded word, and why it seems to be such a complicated issue (not just in terms of theory of mind, but in general).&lt;/p&gt;

&lt;p&gt;Gopnik &amp;amp; Wellman seem to really be proposing what is a &lt;em&gt;computational-level&lt;/em&gt; analysis of theory of mind: we begin with theories based on our initial capabilities (i.e., perception) and urges (i.e., desires). The problem is then to update those theories as new information comes along. The specific changes that Gopnik &amp;amp; Wellman predict are really predictions about how a particular solution to that problem ends up playing out.&lt;/p&gt;

&lt;p&gt;The simulation theorists (&lt;a href=&quot;/quals/theory%20of%20mind/2016/01/07/Gordon1992.html&quot;&gt;Gordon&lt;/a&gt; and &lt;a href=&quot;/quals/theory%20of%20mind/2016/01/08/Goldman1992.html&quot;&gt;Goldman&lt;/a&gt;) are proposing a squarely &lt;em&gt;algorithmic-level&lt;/em&gt; account. It is highly mechanistic and focuses on the solution as a particular algorithm (the one that is already implemented by our brains), though it is vague on the specific representation of inputs and outputs (beliefs, desires, perceptions, decisionse—but it is not clear exactly what forms those take).&lt;/p&gt;

&lt;p&gt;In constrast, simulation &lt;em&gt;can&lt;/em&gt; actually be the (approximate) solution to a computational-level problem. In physical simulation, the computational-level problem can be expressed analytically as a differential equation, but it cannot be solved analytically. Numerical simulation, though an approximation, is the only known way to solve the problem short of setting up the actual physical situation in the real world. In probabilistic simulation, the story is similar. The computational-level problem can be expressed analytically, but often cannot be solve analytically. Monte-Carlo simulation is one particular class of methods for approximating the solution.&lt;/p&gt;

&lt;p&gt;Thus, sometimes simulation is the correct approach when it is the approximate solution to a computational-level problem. However, it is not &lt;em&gt;always&lt;/em&gt; the right answer, and is certainly not the right solution &lt;em&gt;a priori&lt;/em&gt;. In particular, I think it is a mistake to talk about simulation as being the right solution just on the basis of having a black-box mechanism at our disposal. Just because a tool might be available for use doesn’t make it the &lt;em&gt;right&lt;/em&gt; tool to use. I think instead of talking about whether simulation is the mechanism that is used by the mind in some particular case, the discussion should be about what the &lt;em&gt;best&lt;/em&gt; thing to use would be, and whether that happens to be simulation or not.&lt;/p&gt;
</description>
        <pubDate>Fri, 08 Jan 2016 06:10:48 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/08/Gopnik1992.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/08/Gopnik1992.html</guid>
        
        
        <category>Theory of mind</category>
        
      </item>
    
      <item>
        <title>In defense of the simulation theory</title>
        <description>&lt;p&gt;&lt;span id=&quot;Goldman1992&quot;&gt;Goldman, A. I. (1992). In Defense of the Simulation Theory. &lt;i&gt;Mind And Language&lt;/i&gt;, &lt;i&gt;7&lt;/i&gt;(1-2), 104–119. doi:10.1111/j.1468-0017.1992.tb00200.x&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Goldman replies to &lt;a href=&quot;/quals/theory%20of%20mind/2016/01/07/Stich1992.html&quot;&gt;Stich &amp;amp; Nichols&lt;/a&gt;, conceding some of the points they make but also providing further evidence for simulation theory.&lt;/p&gt;

&lt;p&gt;Goldman begins by first pointing out that the simulation theory isn’t a substantial departure from previous approaches in cognitive science, as it falls under the umbrella of &lt;em&gt;knowledge-poor&lt;/em&gt; approaches (e.g. heuristics and biases) in contrast to &lt;em&gt;knowledge-rich&lt;/em&gt; approaches (e.g. rules and symbols). Thus, the simulation theory isn’t a “radical departure” from other paradigms in cognition.&lt;/p&gt;

&lt;p&gt;In the next section, Goldman points out that theory theory, as described by Stich &amp;amp; Nichols, depards substantially from other formulations of the theory theory. For example, he states that “in the philosophical literature it has been widely assumed that it should be easy to formulate the principles of folk psychology because they are &lt;em&gt;platitudes&lt;/em&gt;, i.e. truths that are obvious to everyone” (pg. 106). Additionally, Goldman discusses “the assumption that folk psychological platitudes are culturally produced and culturally transmitted” (pg. 106-7). Both of these claims seem dubious, and presumably Stich &amp;amp; Nichols woult not adhere to either of them. Thus, their definition of theory theory isn’t the same as everyone else’s. So, while criticisms of claims like those don’t necessarily “knock-down” the theory theory, “these arguments do cast doubt on some popular variations of the theory-theory theme, and highlight the difficulties that must be met by any detailed development of the theory-theory” (pg. 108).&lt;/p&gt;

&lt;p&gt;Next, Goldman discusses the relationship to simulations in other domains (i.e., mental imagery). Here he makes the distinction between &lt;em&gt;process-driven&lt;/em&gt; and &lt;em&gt;theory-driven simulation&lt;/em&gt;, and concedes that mental simulation may indeed be theory-driven; thus, it is necessary to show that the simulation theory is process driven, not just that it is a simulation. This leads into a discussion on introspection, which cannot on its own be used to discriminate between process- and theory-driven simulations. Goldman argues that, for the present purposes, the point of introspection isn’t to distinguish between the two, just to show that theory of mind may indeed involve some form of simulation (as a first step).&lt;/p&gt;

&lt;p&gt;Goldman next responds to Stich &amp;amp; Nichols point about simplicity, which was that the theory theory gets the control mechanism “for free” while simulation theory gets the database “for free”. He makes a good point that it isn’t entirely clear what “for free” means, and argues that simulation theory does indeed get the control “for free” by arguing that the process that interprets the output of the decision-making process needs to be present for any theory, and thus it would indeed be available to off-line simulation as well. (I think Goldman misses the point of what “control” means here, but I’ll get back to this in the takeaways section).&lt;/p&gt;

&lt;p&gt;Next, Goldman discusses additional evidence from autism for simulation theory. Specifically, that there is evidence that autistic children are perfectly capable at theorizing about mechanistic or behavioral processes (just not mentalistic ones), and that they do have a concept of desire, but that they have difficulty evaulating what is a “reasonable” desire based on the situation. He concludes that these pieces of evidence are easily explained by simulation theory, but not theory theory.&lt;/p&gt;

&lt;p&gt;He also discusses the developmental literature discussed by Stich &amp;amp; Nichols, and argues that the results they cite are contradicted by other studies and may be due to confusing task demands. He also suggests the possibility that younger children may understand beliefs, but do not classify those beliefs as being the same as &lt;em&gt;knowledge&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Finally, Goldman replies to Stich &amp;amp; Nichols’ arguments about cognitive penetrability, and in particular, the claim that simulations should predict the same impenetrable behaviors that people exhibit when they make predictions about others. Goldman argues that this only should be the case if the inputs to the simulation are &lt;em&gt;identical&lt;/em&gt; to when people are in the situation themselves, and only if the interpretation of those simulations is identical as well. He questions whether this would actually be the case in the examples cited by Stich &amp;amp; Nichols.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;I like Goldman’s further characterization of simulation as being either &lt;em&gt;theory-driven&lt;/em&gt; or &lt;em&gt;process-driven&lt;/em&gt;. That is, the simulation is either driven from a theory (and therefore is something like a simulation of a mental model), or it is actually an execution of a real process in the brain. In the latter case I wonder if it is even really appropriate to call it “simulation”, as it’s not a &lt;em&gt;simulation&lt;/em&gt; of the process by which you would act, it &lt;em&gt;is&lt;/em&gt; the process by which you would act. A &lt;em&gt;simulation&lt;/em&gt; actually implies that it is a copy of a process that necessarily makes certain assumptions and simplifications. I guess it is a simulation in the sense that the real process is being used in the &lt;em&gt;context&lt;/em&gt; of a simulation (i.e., pretend inputs).&lt;/p&gt;

&lt;p&gt;In discussing the role of the controller, I think Goldman misses the point of why this is important. I made this point in my notes on &lt;a href=&quot;/quals/theory%20of%20mind/2016/01/07/Gordon1992.html&quot;&gt;Gordon&lt;/a&gt; as well: knowing what “pretend” inputs to feed the simulation is a nontrivial task. It cannot simply be a matter of trial-and-error. There has to be some additional mechanism guiding the decisions to change certain dimensions of the input rather than others, and what they get changed &lt;em&gt;to&lt;/em&gt;. This is related to the difficult problem of determining what information is relevant and what information is irrelevant; knowing the answer to these questions requires some sort of higher-level abstract knowledge (like a theory!).&lt;/p&gt;

&lt;p&gt;I do think Gordon brings up some good points regarding empathy. For example, people often feel physiological pain when they see someone else in pain (e.g. if you watch a video of someone cutting their finger with a knife while cutting vegetables, it &lt;em&gt;feels&lt;/em&gt; painful to see). Thus, it is not implausible that there is some amount of processing that goes on that engages the same systems that we use when where are in the situation ourselves. However, I don’t think this can be the only explanation. There are also cases where we understand someone else’s behavior while feeling relatively apathetic about it. If I simply read “John cut his finger”, I don’t feel physical pain, but if I see a video of the same thing happening, I do (though, of course, even that is still not as painful as actually experiencing it). But, I still understand how John is feeling in either case. Based on the arguments of Gordon and Goldman, I don’t see how just reading “John cut his finger” would be something that could be fed into the simulator without actually constructing the full scenario (i.e. putting it into a format that the simulation can handle), in which case it ought to predict that you would feel pain.&lt;/p&gt;

&lt;p&gt;This whole debate seems so black-and-white, though. Why does it have to be &lt;em&gt;only&lt;/em&gt; theory-theory, or &lt;em&gt;only&lt;/em&gt; simulation theory? Is it really so impossible for there to be some combination of using higher-order structured knowledge (i.e., a theory) in combination with reuse of existing perceptual, motor, or emotional systems (i.e., simulation)?&lt;/p&gt;
</description>
        <pubDate>Fri, 08 Jan 2016 03:29:43 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/08/Goldman1992.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/08/Goldman1992.html</guid>
        
        
        <category>Theory of mind</category>
        
      </item>
    
      <item>
        <title>Folk psychology: simulation or tacit theory?</title>
        <description>&lt;p&gt;&lt;span id=&quot;Stich1992&quot;&gt;Stich, S. P., &amp;amp; Nichols, S. (1992). Folk Psychology: Simulation or Tacit Theory? &lt;i&gt;Mind And Language&lt;/i&gt;, &lt;i&gt;7&lt;/i&gt;(1-2), 35–71. doi:10.1111/j.1468-0017.1992.tb00196.x&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Stich &amp;amp; Nichols argue against simulation theory in favor of theory theory. They first give an overview of their interpretation of what simulation theory is positing, which seems consistent with what I’ve read so far. They make a particular point about calling the simulation theory &lt;em&gt;off-line simulation&lt;/em&gt; of the decision-making system. That is, they argue that simulation theory says that to run a simulation, the decision-making system is taken off-line. It is fed pretend beliefs and desires, and it outputs a decision, which is then fed to another system which explains and interprets decisions in terms of their inputs. They also clarify what they mean by “theory”, which is (as they put it) in the “wide” sense: that a theory need not necessarily be symbolic/logical, but could take the form of other representations like a neural network as well.&lt;/p&gt;

&lt;p&gt;Stich &amp;amp; Nichols go through a number of arguments for the simulation theory, and give counter evidence to each one.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;What are the rules of the folk psychological theory?&lt;/em&gt; This is interpreting a “theory” in the narrow sense. And besides, not being able to specify the rules doesn’t make the theory invalid (example: language, folk physics).&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Mental simulation models have been successful.&lt;/em&gt; “Simulation” used in the context of “mental simulation” is actually closer to a theory that is ust not rule/sentence like.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Children can’t possibly have as sophisticated a theory as theory theory suggests.&lt;/em&gt; Theory theory doesn’t necessarily posit a theory that is the same type of stuff that you learn in the classroom. Besides, children learn other very complicated things (language, folk physics)&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Simulation theory is simpler than theory theory.&lt;/em&gt; Specifying the “control mechanism” for coming up with pretend beliefs and desires is non-trivial. Essentially, in theory-theory, you get the control for free, while in simulation theory, you get the “database” of knowledge for free. They are equally complex theories.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Sometimes we imagine how others behave by imagining ourselves in their situation.&lt;/em&gt; Imagery is not the same thing as simulation. For example, to imagine yourself walking through your house and counting the number of windows, it’s not just running an off-line simulation—the knowledge about the number of windows has to come from somewhere.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Simulation theory is supported by developmental evidence.&lt;/em&gt; It is consistent with the evidence; that doesn’t it predicts it. Theory theory is also consistent with the evidence.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Autistic children are poor at engaging in pretend play and at reasoning about theory of mind.&lt;/em&gt; As in the previous point, simulation might be able to account for this, but so can theory theory.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After refuting the arguments of off-line simulation theory, Stich &amp;amp; Nichols present a few arguments in favor of theory theory:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;There is developmental data that simulation theory can’t explain.&lt;/em&gt; In particular, there is evidence that children have accurate knowledge about what other children have seen and yet still make incorrect judgments about their beliefs. That is, it seems like children have all the correct inputs that would be used to run an off-line simulation, yet they still come up with the wrong answer, but only for &lt;em&gt;other&lt;/em&gt; people—they give a different answer themselves.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Theory theory is cognitively penetrable.&lt;/em&gt; Simulation theory is not cognitive penetrable. In particular, because it’s a simulation of one’s own behavior, if there are any quirks in our own behavior that we don’t consciously know about, they should still show up in our predictions of other people’s behavior. However, if the theory posited by theory theory doesn’t include these things explicitly, then it will make the wrong predictions because it is cognitively penetrable. There are many examples of cases where people predict that they (or others) would behave in a certain way, but then actually behave differently themselves. Thus the can’t have just been running a simulation.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;I agree with pretty much all the points made by Stich &amp;amp; Nichols, though I do think they are a bit vague on the notion of what a theory is. Ideally, even if you can’t specify a set of rules, you should still be able to roughly sketch the mechanism by which it works, or by which it is acquired.&lt;/p&gt;

&lt;p&gt;I do like how Stich &amp;amp; Nichols explicitly contrast offline simulation with other forms of simulation. They state that they don’t think offline simulation is involved at all, which I would probably agree with—though I do think some form of “simulation” probably is used. Perhaps the better term to use here is “emulation” (ala &lt;a href=&quot;/quals/mental%20imagery/2016/01/01/Grush2004.html&quot;&gt;Grush&lt;/a&gt;), to imply that it is a simulation from a &lt;em&gt;model&lt;/em&gt;, not a simulation from &lt;em&gt;oneself&lt;/em&gt;. Such a model could easily be a component in a theory; thus, this notion isn’t at odds with theory theory.&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Jan 2016 11:25:00 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/07/Stich1992.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/07/Stich1992.html</guid>
        
        
        <category>Theory of mind</category>
        
      </item>
    
      <item>
        <title>The simulation theory: objections and misconceptions</title>
        <description>&lt;p&gt;&lt;span id=&quot;Gordon1992&quot;&gt;Gordon, R. M. (1992). The Simulation theory: Objections and misconceptions. &lt;i&gt;Mind And Language&lt;/i&gt;, &lt;i&gt;7&lt;/i&gt;(1-2), 11–34. doi:10.1111/j.1468-0017.1992.tb00195.x&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Gordon attempts to define his own definition of &lt;em&gt;simulation theory&lt;/em&gt; (ST), and contrasts it with &lt;em&gt;theory theory&lt;/em&gt; (TT) as well as other forms of ST (“putting oneself in their shoes”, the Model Model).&lt;/p&gt;

&lt;p&gt;First, Gordon explains why ST is not “putting oneself in the other’s place”. He says that ST is not this, because people don’t actually put themselves in others’ places most of the time (usually they are &lt;em&gt;told&lt;/em&gt; to do that). Rather, being told to put oneself in the other’s place means that “you shouldn’t just project your own situation and psychology on the other”. This implies that, to begin with, you &lt;em&gt;are&lt;/em&gt; projecting your own situation and psychology on the other, which is the core of what ST is about.&lt;/p&gt;

&lt;p&gt;Gordon goes on to explain what he means by &lt;em&gt;projection&lt;/em&gt;, and specifically, &lt;em&gt;total projection&lt;/em&gt;. Total projection is the idea of projecting your own situation and psychology onto someone else, without making any adjustment (spatial or otherwise). This type of total projection is the default mode of simulation. In using projection, we search for explanations that would have caused ourselves to behave in the same way as other people. We can also adjust these projections in order to better explain other people’s actions, for example by imagining ourselves in their spatial location:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In general terms, what you are doing is shifting the locations and vectors of environmental features on your egocentric map—that is, the mental map in which things and events are represented in relation to yourself, here, and now—so as properly to engage your location-specific or vector-specific tendencies to action or emotion.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Alternately, you can “prep” yourself to have the appropriate attitudes or beliefs that would be necessary to understand the behavior of others. For example, to understand why someone likes the music of a particular artist that you do not particularly like, you find a suitable alternative that you enjoy to a similar degree and then use that alternative as a stand in for understanding the other person’s intentions (e.g. to go see that person in concert). Importantly, because we can make these adjustments to the projection, this allows us to simulate counterfactuals, which allows us to generate appropriate explanations.&lt;/p&gt;

&lt;p&gt;Gordon contrasts ST with the idea that we might just use generalizations or laws to explain other people’s behavior. He argues that this cannot be the case, as generalizations/laws on their own are too brittle; we need to know when they are relevant so that we can appropriately apply them. Knowing when to apply them requires using our own knowledge about how the world works; this therefore ends up being just another way of using projection.&lt;/p&gt;

&lt;p&gt;He also contrasts ST with the “Model” Model, which is the idea that simulation is just a model that you can use to run simulations (similar to running a simulation on a model of an airplane). Gordon argues that with the “Model” Model, you &lt;em&gt;would&lt;/em&gt; need something like a theory to explain the outputs of the model, as it is essentially a black box. But, under the hypothesis of projection, this is not necessary because you yourself already understand the workings of the model because you &lt;em&gt;are&lt;/em&gt; the model.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;From a computational standpoint, it is really difficult to see how Gordon’s version of the ST would work. It seems that the core of his argument is that because we are projecting ourselves, we get for free the ability to generate explanations of behavior. I don’t think this follows, and in particular, it still doesn’t give us any insight into how those explanations are generated (it feels a bit like saying, “we generate explanations of other people’s behavior by using ourselves to generate explanations of other people’s behavior”). I also think he doesn’t give enough credit to the difficulty in knowing what things about the projection to change. He basically implies it is as simple as “trying out various options until one clicks”, but for a given scenario there might be many possible things you could try to change. How do you know which dimension requires modification? And then how do you know the right modification to make? And then what does it mean for an explanation to “click”? What is a “good enough” explanation? All of these things seem like they need some form of metacognition or higher-level, structured knowledge—for example, a theory.&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Jan 2016 09:42:08 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/07/Gordon1992.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/theory%20of%20mind/2016/01/07/Gordon1992.html</guid>
        
        
        <category>Theory of mind</category>
        
      </item>
    
      <item>
        <title>Representational momentum and related displacements in spatial memory: a review of the findings</title>
        <description>&lt;p&gt;&lt;span id=&quot;Hubbard2005&quot;&gt;Hubbard, T. L. (2005). Representational momentum and related displacements in spatial memory: A review of the findings. &lt;i&gt;Psychonomic Bulletin And Review&lt;/i&gt;, &lt;i&gt;12&lt;/i&gt;(5), 822–851. doi:10.3758/BF03196775&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;Hubbard consolidates a huge body of literature regarding the phenomena of &lt;em&gt;displacement&lt;/em&gt;. While this has sometimes been referred to as &lt;em&gt;representational momentum&lt;/em&gt;, Hubbard prefers the term “displacement” because the effect can be found in many domains:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Forward displacement (in the direction of motion)&lt;/li&gt;
  &lt;li&gt;Downward displacement (due to gravity)&lt;/li&gt;
  &lt;li&gt;Reduced displacement after contact (due to friction)&lt;/li&gt;
  &lt;li&gt;Inward displacement along a curved trajectory (due to centripetal force)&lt;/li&gt;
  &lt;li&gt;Displacement in auditory pitch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are many variables that seem to influence the amount and direction of displacement:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Target velocity (increased velocity increases displacement)&lt;/li&gt;
  &lt;li&gt;Direction of motion (horizontal displacement is typically greater than vertical displacement, and vertical displacement is affected by gravity)&lt;/li&gt;
  &lt;li&gt;Target identity and shape (displacement tends to be consistent with the typical direction certain shapes move)&lt;/li&gt;
  &lt;li&gt;Target weight (larger downward displacement for larger objects)&lt;/li&gt;
  &lt;li&gt;Target animacy&lt;/li&gt;
  &lt;li&gt;Surrounding context (e.g. if there are “landmarks”, if the stimuli are realistic scenes, if the motion is from the point of view of an observer, etc.)&lt;/li&gt;
  &lt;li&gt;Physical constraints (e.g. walls that the object can bounce off of)&lt;/li&gt;
  &lt;li&gt;Structure of the motion (e.g. oscillitory motion)&lt;/li&gt;
  &lt;li&gt;Internal vs. externally caused motion, as in the launching task&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is also influenced by factors applying to the participant themselves:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Attention&lt;/li&gt;
  &lt;li&gt;Fixation point (eye movements)&lt;/li&gt;
  &lt;li&gt;Action plans&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Methodologically, displacement has been found for smooth-moving targets, for sequential series of discrete stimuli, for static images that imply motion, and for targets whose motion is controlled by the participant. The effect of displacement seems to decay after a period of time, though the results on this are somewhat mixed. Response measures have included judging same/different, clicking on the remembered position of the target, or reaching for the target.&lt;/p&gt;

&lt;p&gt;Hubbard suggests that displacement does not solely reflect objective physical laws, though it might strongly be influenced by them. Importantly, this is because displacement can be affected by other factors (such as landmarks, or whether the motion is internally or externally caused) besides just kinematics and dynamics. Regarding naive physics, he suggests that “displacement might reflect subjective consequences of physical principles, rather than objective physical principles per se” (pg. 842).&lt;/p&gt;

&lt;p&gt;In terms of a computational-level theory of displacement, Hubbard suggests that displacement serves the purpose of bridging the gap between perception and action by helping to localize the future spatial locations of objects. This is consistent with the idea of forward models, though displacement seems to often be less than what one would expect from an accurate prediction into the future. Hubbard suggests this might be a tradeoff for prediciting motion that is either predictable or unpredictable: some displacement helps bias action towards predictable motion, but it is also less than what would be expected, which makes it easier to recover when the motion is unpredictable.&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;I would be really curious to see if you could get the effects of displacement from a computational-level model whose goal is to execute an action to “catch” a moving object. This would involve predicting the next state of an object based on a variety of factors (position, rotation, velocity, shape, etc.) but also executing the action (with a latency similar to that found in humans). Would you end up finding the same types of displacement effects? Would this model predict new things about displacement?&lt;/p&gt;

&lt;p&gt;Additionally, I wonder to what extent displacement/prediction is used simply as a tracking device. That is, it’s not used to inform the motor system of where to execute its action—just to help the perceptual system track the object through time.&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Jan 2016 07:41:52 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/representational%20momentum/2016/01/07/Hubbard2005.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/representational%20momentum/2016/01/07/Hubbard2005.html</guid>
        
        
        <category>Representational momentum</category>
        
      </item>
    
      <item>
        <title>Representational momentum</title>
        <description>&lt;p&gt;&lt;span id=&quot;Freyd1984&quot;&gt;Freyd, J. J., &amp;amp; Finke, R. A. (1984). Representational Momentum. &lt;i&gt;Journal Of Experimental Psychology: Learning, Memory, and Cognition&lt;/i&gt;, &lt;i&gt;10&lt;/i&gt;(1), 126–132. doi:10.1037/0278-7393.10.1.126&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this paper, Freyd &amp;amp; Finke present a number of experiments showing an effect of &lt;em&gt;representational momentum&lt;/em&gt; in which people’s memories for the position/rotation of an object are distorted in the direction of implied motion of the object.&lt;/p&gt;

&lt;h1 id=&quot;methods&quot;&gt;Methods&lt;/h1&gt;

&lt;p&gt;In Experiment 1, they showed participants a sequence of four images and asked them to determine whether the third and fourth images were the same or different. The first three images showed a rectangle in different orientations resulting from rotating it in a particular direction. The fourth image was either the same as the third, or rotated slightly forward or backwards from the third image (though not as much as the angular separation between the first three images). Freyd &amp;amp; Finke found that people were significantly faster and more accurate at judging the same (15.8% error) and reverse (6.4% error) stimuli, compared to the forward (43.9% error) stimuli.&lt;/p&gt;

&lt;p&gt;In Experiment 2, they controlled for the effect of the result being somehow due to “some configural property of the inducing displays, independent of their temporal order”. Thus, they swapped the first and second images in the presentation. This caused the representational momentum effect to disappear entirely.&lt;/p&gt;

&lt;p&gt;In Experiment 3, Freyd &amp;amp; Finke asked whether the representation momentum effect was due to sensory or cognitive processing. To test this, they increased the ISI (inter-stimulus interval) times to 500ms and 750ms (from 250ms). With these larger times, they still found the representational momentum effects, though they were less strong than at 250ms.&lt;/p&gt;

&lt;p&gt;They additionally ran another control study to see if it was just whether people were extrapolating forward to the next image in the sequence (after the first three images). Instead of having small perturbations to the rotation of the third image, they used the next image in the sequence. They did not find the representational momentum effect using these larger rotations.&lt;/p&gt;

&lt;h1 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h1&gt;

&lt;p&gt;n/a&lt;/p&gt;

&lt;h1 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h1&gt;

&lt;p&gt;There seems to be something about people’s predictive processing of visual stimuli that causes them to misremember the location or pose of objects. I wonder if something like this could be explained by a system that, rather than storing the actual current perception, stores an expectation for the next perception. If there has recently been motion, then this would give rise to something like the representational momentum effect. It doesn’t quite fit with their experimental setup, though, which is that they showed each image for 250ms, then removed it for 250ms, then showed the next, etc. These long presentation times mean that apparent motion isn’t generated, so it doesn’t seem as if people are estimating the angular velocity and then propagating that forward—if they were, then presumably the last control experiment that Freyd &amp;amp; Finke found would have still found the effect. Perhaps one explanation for this is that the visual system is estimating velocity from the implied motion, but it only propagates it for a fraction of the time forward—i.e., it doesn’t estimate the ISI time and factor that in. If this were the case, then it should be possible to demonstrate that different angular velocities result in memory distortions that are either closer or further away from the true image.&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Jan 2016 05:54:51 -0800</pubDate>
        <link>http://jhamrick.github.io/quals/representational%20momentum/2016/01/07/Freyd1984.html</link>
        <guid isPermaLink="true">http://jhamrick.github.io/quals/representational%20momentum/2016/01/07/Freyd1984.html</guid>
        
        
        <category>Representational momentum</category>
        
      </item>
    
  </channel>
</rss>
