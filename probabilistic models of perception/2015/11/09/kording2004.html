<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Bayesian integration in sensorimotor learning</title>
    <meta name="description" content="Notes on readings for my qualifying exams.
">

    <link rel="stylesheet" href="/quals/css/main.css">
    <link rel="canonical" href="http://jhamrick.github.io/quals/probabilistic%20models%20of%20perception/2015/11/09/kording2004.html">

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });
    </script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/quals/">Quals Reading Notes</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/quals/about/">About</a>
          
        
          
          <a class="page-link" href="/quals/categories/">Categories</a>
          
        
          
        
          
        
          
        
        <a class="page-link" href="/quals/readings.pdf">Reading List</a>
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Bayesian integration in sensorimotor learning</h1>
    <p class="post-meta">Nov 9, 2015</p>
  </header>

  <article class="post-content">
    <p><span id="Kording2004">Körding, K. P., &amp; Wolpert, D. M. (2004). Bayesian integration in sensorimotor learning. <i>Nature</i>, <i>427</i>(6971), 244–247. doi:10.1038/nature02169</span></p>

<h1 id="summary">Summary</h1>

<p>Körding &amp; Wolpert ask the question: do people account for both the statistics of the environment as well as perceptual uncertainty when engaged in a motor learning task? They proposed three models for how participants could be taking these various factors into account:</p>

<ol>
  <li>Full compensation – upon receiving feedback, participants fully adjust by the difference between their observation and where their finger would have been if there were no lateral shift. This model predicts that the final displacement error will be zero-mean with variance just based on the perceptual uncertainty.</li>
  <li>Bayesian probabilistic – participants optimally combine information about the prior distribution and the uncertainty of visual feedback. This predicts that the final displacement error should increase as uncertainty increases.</li>
  <li>Mapping – participants learn a mapping between feedback and the lateral shift, which essentially means that they adjust by the mean of the prior (but do not take into account perceptual uncertainty) plus uncertainty from “intrinsic processes”.</li>
</ol>

<p>They find that participants’ deviations from the target did change as a function of the perceptual uncertainty, indicating that they must have taken it into account, and therefore ruling out models 1 and 3. Model 2 is consistent with the empirical results.</p>

<p>I don’t entirely understand why they expect the slope to be non-zero in the case of $\sigma_0$ and model 3. I think it’s because they say “the uncertainty comes from intrinsic processes only”, but they don’t go into details as to what this means exactly, or what that uncertainty is, beyond saying that if that Bayesian model is assumed, then the visual uncertainty for $\sigma_0$ is $0.36\pm 0.04$.</p>

<h1 id="methods">Methods</h1>

<p>Participants had to point to a target. However, they could (in general) not see the movement of their finger while doing so. There were four types of trials:</p>

<ul>
  <li>$\sigma_0$ – exact feedback given at the midway point, and also at the end of the trial (single white dot)</li>
  <li>$\sigma_M$ – blurred feedback with medium variance given at the midway point (25 transluscent dots with standard deviation of 1cm)</li>
  <li>$\sigma_L$ – blurred feedback with large variance given at the midway point (25 translucent dots with standard deviation of 2cm)</li>
  <li>$\sigma_\inf$ – no feedback given</li>
</ul>

<p>Additionally, the feedback was always displaced laterally by an amount drawn from the distribution $\mathcal{N}(1, 0.5)$. So, there was so “true” displacement, as well as random noise in the observation of their finger position. Final finger positions were recorded.</p>

<p>They also ran another experiment in which the prior distribution was bimodal, rather than a Gaussian centered at 1cm. Participants seemed to adapt to this distribution as well.</p>

<h1 id="algorithm">Algorithm</h1>

<p>The goal is to estimate a distribution for the true displacement $x_{true}$, based on the observed $x_{sensed}$:</p>

<script type="math/tex; mode=display">
p(x_{true}|x_{sensed})\propto\mathcal{N}(x_{sensed}; x_{true}, \sigma_{sensed})\mathcal{N}(x_{true}; 1\mathrm{cm}, \sigma_{prior})
</script>

<p>The MAP estimate of this distribution is then:</p>

<script type="math/tex; mode=display">
x_{estimated}=\frac{\sigma^2_{sensed}}{\sigma^2_{sensed}+\sigma^2_{prior}}[1\mathrm{cm}]+\frac{\sigma^2_{prior}}{\sigma^2_{sensed}+\sigma^2_{prior}}x_{sensed}
</script>

<p>I think that $\sigma_{sensed}$ here isn’t necessarily exactly the exact uncertainty from $\sigma_0$, $\sigma_M$, and $\sigma_L$, but a combination of that as well as intrinsic motor and/or perceptual uncertainty.</p>

<h1 id="takeaways">Takeaways</h1>

<p>In motor learning tasks, people adapt to the statistics of the world that they are interacting with. They are able to learn about the uncertainty in processes affecting their movement (in this case, lateral movement, but this could also potentially be something like wind or the mass of an object inhibiting movement), whether that be a regular Gaussian distribution, or even a bimodal distribution. Moreover, people take into account sensory uncertainty – both their own (arising from noise in perceptual/motor processes?) and that imposed by the experimenter. Being able to account for this sensory uncertainty could be useful in learning how to deal with distorted perceptions (e.g. angle of refraction when looking into water, perhaps?). In particular, this adaption seems to be consistent with optimal Bayesian integration of prior and sensory uncertainty.</p>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Quals Reading Notes</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>Quals Reading Notes</li>
          <li><a href="mailto:"></a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/jhamrick">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">jhamrick</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/jhamrick">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">jhamrick</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">Notes on readings for my qualifying exams.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
