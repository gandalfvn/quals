\documentclass[12pt]{article}
\input{heading}
\begin{document}

\question{What are probabilistic models of cognition? Please begin by situating them with respect to alternatives (i.e., what are non-probabilistic models of cognition?). Then describe what you see as the two or three key strengths of this approach, illustrating each with examples.}

% \question{What do you see as the major challenges for probabilistic models of cognition? Outline at least two significant problems for this approach, and how you think those problems could potentially be addressed through future research.}

\subsection*{Introduction}

On the surface, probabilistic models of cognition are an application of Bayesian inference to modeling how people reason about the world. In particular, rather than viewing Bayes' rule in the traditional sense as $P(A|B)\propto P(B|A)P(A)$, probabilistic models of cognition assign a particular meaning to the variables as hypotheses ($H$) and data ($D$). With this interpretation, Bayes' rule becomes $P(H|D)\propto P(D|H)P(H)$. The significance of writing Bayes' rule in this way is that it gives us a framework for describing how people reason about the world by combining prior knowledge about the world (or \textit{inductive bias}) with new observations \citep{Griffiths2010}.

However, probabilistic models of cognition are much more than a simple application of Bayes' rule. I will argue that the strengths of probabilistic models lie in their ability to express complex, \textit{structured representations} and to formalize explicit hypotheses about how people think the world works in terms of their \textit{generative knowledge}. Probabilistic models of cognition are further strengthened by the strategy of \textit{rational analysis} that is commonly used to construct them.

Here, I will begin by discussing the distinction between probabilistic models of cognition and non-probabilistic models of cognition. Second, I will explain how structured representations allow probabilistic models to capture complex forms of knowledge. Third, I will discuss how that knowledge may capture not just the structure of data and hypotheses, but of the generative process by which the data itself is created. Fourth, I will consider how the strategy of rational analysis provides a principled way of constructing probabilistic models.

\subsection*{What are non-probabilistic models of cognition?}

Before jumping in to describing what are \textit{non} probabilistic models of cognition, I will briefly summarize one way in which models can be distinguished: that is, what level of analysis they are posed at \citep{Marr1971}. Marr's levels of analysis consist of the \textit{computational} level (at which analyses are concerned with what the goal of a system is, and what the solution might look like), the \textit{algorithmic} level (at which analyses are concerned with specific processes by which a solution to the goal can be computed), and the \textit{implementation} level (at which analyses are concerned with the physical realization of the solution).

Non-probabilistic models of cognition usually fall at the \textit{algorithmic} level of analysis: they are frequently committed to a particular type of representation. For example, connectionist models are committed to using distributed representations and a process of error-driven learning (gradient descent via backpropagation). In another example, the model theory \citep{Johnson-Laird2012} is committed to a representation in terms of ``mental models'' and to processes which manipulate those mental models. Qualitative reasoning models are committed to ``qualitative'' representations of knowledge such as the knowledge that $X>Y$, but not specific values of $X$ or $Y$ \citep{Kuipers1986,Forbus2011}. Models of heuristics and biases \citep{Kahneman1973,Tversky1974} typically assume a particular type of process or representation that might cause such systematic errors.

All of the examples listed above either make a strong commitment to a particular \textit{algorithm} (e.g., backpropagation), to a particular \textit{representation} (e.g., distributed representation), or to both. In contrast, probabilistic models of cognition are almost always formulated at the \textit{computational} level of analysis and typically do not make assumptions about processes, though they may make abstract assumptions about representation. Probabilistic models of cognition, while formulated in terms of Bayesian models, do not make assumptions about the specific process by which those inferences are computed: for example, if a process-level model of response time and accuracy can be described as performing Bayesian inference \citep{Bitzer2014}, then it is not inconsistent with a probabilistic model formulated at the computational level.

It is important to differentiate the types of representations assumed by computational-level probabilistic models from the representations assumed by algorithmic-level models: the representations used by probabilistic models are concerned with the \textit{structure} of information rather than a particular \textit{encoding}. For example, a probabilistic model might assume a representation involving a causal Bayes' net \citep{Griffiths2009}, but it is agnostic as to whether that representation is actually instantiated as a set of distributed activations in a neural network, or as a logical set of nodes and edges, or as a matrix, etc.\footnote{There are some probabilistic models that do seem to make stronger commitments about the type of representation. For example, \cite{Kemp2010} assume knowledge to be represented in a binary matrix or tensor. I would interpret this assumption to not be a core piece of the model, however, as long as whatever representation was used somehow expressed relationships between pairs of entities. In order to actually compute the model predictions, a specific representation must sometimes be chosen.}

\subsection*{Structured representations}

One of the core strengths of probabilistic models are their ability to express abstract, structured representations. By interpreting Bayes' rule in terms of hypotheses and data, probabilistic models have the option of formulating the structure of hypotheses and data in whatever way is most relevant to the problem at hand. Here, I will give examples from several papers that formulate probabilistic models in terms of powerful representations.

In their paper on theory-based causal induction, \cite{Griffiths2009} outline a framework for how mental theories (that is, people's own theories about the world, not the modeler's theory about people) might be constructed. \cite{Griffiths2009} take the idea that Bayes' nets can be used for inductive reasoning and show how a probabilistic model operating over the structure of the Bayes' nets themselves can explain inductive inferences about causal structure in the world.

In another example, \cite{Kemp2008} also make use of a graph representation--specifically, a \textit{graph grammar}--to show how people might extract structured representations from data. In this paper, the grammar defines various types of graphs (e.g., chains, trees, hierarchies, etc.) and the probabilistic model over the grammar expresses how a particular graph representation might be chosen for a specific set of data.

Using a different type of grammar, \cite{Ullman2012} express theories in terms of propositions and perform inference over theories with the help of a probabilistic grammar specifying how propositions combine into Horn Clauses to form laws within the theory.

\subsection*{Generative knowledge}

Closely related to the idea of structured representations is the idea of \textit{generative knowledge}. The term ``generative'' is not always used in the same way, so I will attempt to provide a definition of what I mean by ``generative'' in this context. First, in machine learning, a generative model is defined as modeling the joint distribution $P(H,D)$ from which the posterior $P(H|D)$ can be computed. This is in contrast to a discriminative model, which models the posterior distribution directly \citep{Ng2002}. In this sense, most probabilistic models are generative models as they almost always define the full joint distribution. In the context of cognitive science, however, there is a more nuanced interpretation of ``generative''.

\cite{Battaglia2012} make the distinction between the generative \textit{process} and generative \textit{knowledge}. They define the generative process to be the procedure by which the world gives rise to our perceptions, and generative knowledge to be a person's hypothesis about how generative process works. The generative process should be distinguished from structured representations, which apply to the form of the variables in a probabilistic model (e.g., $H$ and $D$). In contrast, the generative process reflects assumptions about the \textit{distributions} and processes by which $H$ is generated or by which $D$ is generated from $H$.

The generative knowledge in a probabilistic model may be relatively simple: for example, knowledge about the statistics of the world. \cite{Griffiths2006} and \cite{Lewandowsky2009} demonstrate that people have detailed knowledge about the empirical distributions of every-day phenomena such as cake baking times, length of poems, or lifespans.

Probabilistic models can also express egocentric generative knowledge, such as the reliability of various sensory cues. This type of generative knowledge has been widely explored in probabilistic models of perception \citep{Battaglia2012}, and has been used to explain phenomena including visual illusions \citep{Weiss2002} and sensory cue integration when the reliability of a cue is manipulated \citep{Ernst2002}. It has further been suggested that such generative knowledge may underlie other perceptual processes such as visual segmentation \citep{Yuille2006} or speech perception \citep{Halle1959,Halle1962,Bever2010}.

Finally, probabilistic models can encode generative knowledge about complex, nonlinear processes such as how physical objects behave \citep{Teglas2011,Sanborn2013,Smith2012}.

\subsection*{Rational analysis}

Given assumptions about structured representations and generative knowledge, a probabilistic model of cognition encodes a highly specific and falsifiable hypothesis about how people reason: hypotheses are structured in \textit{this particular} form, and generative knowledge specifics that hypotheses and data are generated in \textit{this particular} way. However, in general there always exists some probabilistic model that can capture any phenomena; how, then, should one choose \textit{which} probabilistic to act as a hypothesis? The strategy typically taken is that of \textit{rational analysis} \citep{Anderson1990}. The original version of rational analysis proposed by \cite{Anderson1990} argued for constructing models which are optimal solutions to problems posed at the computational level of analysis \citep{Marr1971} while taking into account environmental constraints. This approach has been remarkably successful in generating hypotheses (instantiated as probabilistic models of cognition) for topics ranging from notions of similarity \citep{Tenenbaum2001}, physical intuitions \citep{Teglas2011,Sanborn2013}, perception \citep{Weiss2002,Ernst2002,Kording2004,Yuille2006}, and theory learning \citep{Kemp2007,Griffiths2009,Kemp2010,Ullman2012}, just to name a few domains.

Recently, it has been proposed that rational analysis can go even further than just guiding hypothesis construction at the computational level. \cite{Griffiths2015} suggest a new strategy of \textit{resource-rational analysis}, in which a hypothesis is first generated at the computational level. Second, a class of approximation algorithms are posited for actually computing the solution proposed by the hypothesis. Third, these approximation algorithms are analyzed in order to determine the optimal way to use computational resources under the assumptions of the algorithm. For example, particle filters are an approximation algorithm for Bayesian inference, and they can be analyzed to see \textit{how many} particles are optimal for a bounded agent to use. This approach has already seen success at bridging between the computational and algorithmic levels of analysis, with rational process models suggesting explanations for process-level heuristics and biases such as anchoring \citep{Lieder2012}, availability \citep{Lieder2014}, primacy and recency \citep{Abbott2011}, probability matching \citep{Vul2014}, and theory change \citep{Ullman2012}.

\subsection*{Conclusion}

To summarize, probabilistic models are distinct from non-probabilistic models in that they are posed at the computational level of analysis. Probabilistic models involve two key components: the ability to express structured representations, and the ability to express people's generative knowledge of how the world works. Probabilistic models are further supplemented by the strategy of rational analysis. Although I would argue that rational analysis is not a \textit{component} of probabilistic models of cognition, it is a crucial \textit{strategy} by which hypotheses are selected and refined. In the resource-rational formulation of rational analysis, it additionally strengthens the probabilistic modeling enterprise by helping to connect probabilistic models posed at the computational level to the algorithmic level.

\references
\end{document}
